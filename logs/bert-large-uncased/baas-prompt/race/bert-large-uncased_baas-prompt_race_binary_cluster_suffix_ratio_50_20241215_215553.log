2024-12-15 22:02:14,324 - bert-large-uncased_baas-prompt_race_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 0, 'avg_loss': 1.4403785114385643, 'accuracy': 0.25162337662337664, 'precision': 0.3373210322485881, 'recall': 0.25162337662337664, 'f1': 0.2727182548580999, 'macro_accuracy': 0.25162337662337664, 'macro_precision': 0.24630084233389613, 'macro_recall': 0.24480115053116225, 'macro_f1': 0.22808458975385687, 'question_accuracy': 0.2435064935064935, 'mean_confidence': 0.13227783}
2024-12-15 22:08:23,550 - bert-large-uncased_baas-prompt_race_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 1, 'avg_loss': 1.4602432494260826, 'accuracy': 0.26055194805194803, 'precision': 0.33713797030854875, 'recall': 0.26055194805194803, 'f1': 0.2753780148137793, 'macro_accuracy': 0.26055194805194803, 'macro_precision': 0.25744156381580563, 'macro_recall': 0.26883946725267505, 'macro_f1': 0.24463043819444355, 'question_accuracy': 0.262987012987013, 'mean_confidence': 0.7174756}
2024-12-15 22:14:33,104 - bert-large-uncased_baas-prompt_race_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 2, 'avg_loss': 1.5211179529265133, 'accuracy': 0.2573051948051948, 'precision': 0.36172882436002307, 'recall': 0.2573051948051948, 'f1': 0.2809616768531249, 'macro_accuracy': 0.2573051948051948, 'macro_precision': 0.2591737617313065, 'macro_recall': 0.25188289844803624, 'macro_f1': 0.23473099381233015, 'question_accuracy': 0.25, 'mean_confidence': 0.19817767}
2024-12-15 22:20:42,949 - bert-large-uncased_baas-prompt_race_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 3, 'avg_loss': 1.5313010178397766, 'accuracy': 0.26542207792207795, 'precision': 0.3593194018511428, 'recall': 0.26542207792207795, 'f1': 0.28614406227869504, 'macro_accuracy': 0.26542207792207795, 'macro_precision': 0.2639137343900771, 'macro_recall': 0.2621177935136752, 'macro_f1': 0.24429184942715942, 'question_accuracy': 0.2857142857142857, 'mean_confidence': 0.90963763}
2024-12-15 22:26:51,476 - bert-large-uncased_baas-prompt_race_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 4, 'avg_loss': 1.596911770609308, 'accuracy': 0.2573051948051948, 'precision': 0.3438294840689484, 'recall': 0.2573051948051948, 'f1': 0.2794996023988131, 'macro_accuracy': 0.2573051948051948, 'macro_precision': 0.2516025810047837, 'macro_recall': 0.2459780153390112, 'macro_f1': 0.23312782230403473, 'question_accuracy': 0.2532467532467532, 'mean_confidence': 0.9647083}
2024-12-15 22:32:59,028 - bert-large-uncased_baas-prompt_race_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 5, 'avg_loss': 1.5827372518989853, 'accuracy': 0.2702922077922078, 'precision': 0.3461884983982056, 'recall': 0.2702922077922078, 'f1': 0.2889145451246963, 'macro_accuracy': 0.2702922077922078, 'macro_precision': 0.262594544857971, 'macro_recall': 0.26641649703335896, 'macro_f1': 0.2490256378744765, 'question_accuracy': 0.2564935064935065, 'mean_confidence': 0.96507484}

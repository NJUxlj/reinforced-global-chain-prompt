2024-12-15 23:56:21,815 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 0, 'avg_loss': 1.6324213092264377, 'accuracy': 0.20357142857142857, 'precision': 0.3060758663544994, 'recall': 0.20357142857142857, 'f1': 0.22686532171065787, 'macro_accuracy': 0.20357142857142857, 'macro_precision': 0.18116679297713784, 'macro_recall': 0.17307238361179475, 'macro_f1': 0.16247894937060012, 'question_accuracy': 0.2, 'mean_confidence': 0.3331836}
2024-12-16 00:01:33,214 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 1, 'avg_loss': 1.665384005951254, 'accuracy': 0.20357142857142857, 'precision': 0.314012261650692, 'recall': 0.20357142857142857, 'f1': 0.2278182630773289, 'macro_accuracy': 0.20357142857142857, 'macro_precision': 0.19711023298208172, 'macro_recall': 0.19405505103422102, 'macro_f1': 0.1780949500101972, 'question_accuracy': 0.2, 'mean_confidence': 0.63683605}
2024-12-16 00:06:45,202 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 2, 'avg_loss': 1.7156694888284332, 'accuracy': 0.20357142857142857, 'precision': 0.3087204215276249, 'recall': 0.20357142857142857, 'f1': 0.22870800007445966, 'macro_accuracy': 0.20357142857142857, 'macro_precision': 0.1866076014381099, 'macro_recall': 0.18011155142559654, 'macro_f1': 0.16834798052189354, 'question_accuracy': 0.3, 'mean_confidence': 0.18329597}
2024-12-16 00:11:56,612 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 3, 'avg_loss': 1.7325648192904497, 'accuracy': 0.19642857142857142, 'precision': 0.30110728254796043, 'recall': 0.19642857142857142, 'f1': 0.2165385197170561, 'macro_accuracy': 0.19642857142857142, 'macro_precision': 0.19699550919889902, 'macro_recall': 0.20015632772811634, 'macro_f1': 0.17758328592987405, 'question_accuracy': 0.1, 'mean_confidence': 0.9930479}
2024-12-16 00:17:08,939 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 4, 'avg_loss': 1.8236881141599857, 'accuracy': 0.18928571428571428, 'precision': 0.2856730192671034, 'recall': 0.18928571428571428, 'f1': 0.21511852843239984, 'macro_accuracy': 0.18928571428571428, 'macro_precision': 0.17688920567038888, 'macro_recall': 0.16603029418187795, 'macro_f1': 0.1584897154914715, 'question_accuracy': 0.21428571428571427, 'mean_confidence': 0.75486445}
2024-12-16 00:22:20,464 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 5, 'avg_loss': 1.7528618172203239, 'accuracy': 0.15714285714285714, 'precision': 0.22767717872891607, 'recall': 0.15714285714285714, 'f1': 0.16791467602628452, 'macro_accuracy': 0.15714285714285714, 'macro_precision': 0.15616029715130236, 'macro_recall': 0.16897618293962674, 'macro_f1': 0.14612375629232086, 'question_accuracy': 0.12857142857142856, 'mean_confidence': 0.0084018065}
2024-12-16 00:27:31,506 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 6, 'avg_loss': 1.768365243743909, 'accuracy': 0.18214285714285713, 'precision': 0.26853719003697063, 'recall': 0.18214285714285713, 'f1': 0.20186854611637278, 'macro_accuracy': 0.18214285714285713, 'macro_precision': 0.172109704993253, 'macro_recall': 0.17540308405535368, 'macro_f1': 0.1580116337187958, 'question_accuracy': 0.18571428571428572, 'mean_confidence': 0.34173328}
2024-12-16 00:32:42,314 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 7, 'avg_loss': 1.6912983422608752, 'accuracy': 0.21071428571428572, 'precision': 0.3363266480641786, 'recall': 0.21071428571428572, 'f1': 0.23923427305351685, 'macro_accuracy': 0.21071428571428572, 'macro_precision': 0.20244297174747125, 'macro_recall': 0.1912216886646693, 'macro_f1': 0.17747185688666173, 'question_accuracy': 0.21428571428571427, 'mean_confidence': 0.1126246}
2024-12-16 00:37:55,003 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 8, 'avg_loss': 1.678689781576395, 'accuracy': 0.23214285714285715, 'precision': 0.37506835102462033, 'recall': 0.23214285714285715, 'f1': 0.26765878278283833, 'macro_accuracy': 0.23214285714285715, 'macro_precision': 0.2174281698160208, 'macro_recall': 0.2011200128250114, 'macro_f1': 0.1892708241541266, 'question_accuracy': 0.24285714285714285, 'mean_confidence': 0.11355269}
2024-12-16 00:43:06,359 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 9, 'avg_loss': 1.6862675604459487, 'accuracy': 0.20357142857142857, 'precision': 0.32503367316581105, 'recall': 0.20357142857142857, 'f1': 0.23696993679608874, 'macro_accuracy': 0.20357142857142857, 'macro_precision': 0.18272417624451284, 'macro_recall': 0.1655379675137881, 'macro_f1': 0.15808063515056603, 'question_accuracy': 0.22857142857142856, 'mean_confidence': 0.362821}

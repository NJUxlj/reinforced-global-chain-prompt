2024-12-13 21:57:12,950 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 0, 'avg_loss': 1.4345239308763176, 'accuracy': 0.23863636363636365, 'precision': 0.30772184155314997, 'recall': 0.23863636363636365, 'f1': 0.2582639956683378, 'macro_accuracy': 0.23863636363636365, 'macro_precision': 0.22366188498770545, 'macro_recall': 0.22206020829756967, 'macro_f1': 0.21000582282295477, 'question_accuracy': 0.20454545454545456, 'mean_confidence': 0.55589515}
2024-12-13 21:58:50,561 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 1, 'avg_loss': 1.3968767261366108, 'accuracy': 0.2532467532467532, 'precision': 0.3344093420885752, 'recall': 0.2532467532467532, 'f1': 0.27580816448828027, 'macro_accuracy': 0.2532467532467532, 'macro_precision': 0.24589402146518302, 'macro_recall': 0.23928178274681738, 'macro_f1': 0.22687156274991474, 'question_accuracy': 0.21103896103896103, 'mean_confidence': 0.70269406}
2024-12-13 22:00:28,748 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 2, 'avg_loss': 1.4079726579933056, 'accuracy': 0.2637987012987013, 'precision': 0.3468375885136464, 'recall': 0.2637987012987013, 'f1': 0.2826482292374176, 'macro_accuracy': 0.2637987012987013, 'macro_precision': 0.2600372719825313, 'macro_recall': 0.2653176750761683, 'macro_f1': 0.24346931119427265, 'question_accuracy': 0.23376623376623376, 'mean_confidence': 0.722141}
2024-12-13 22:02:06,146 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 3, 'avg_loss': 1.4111954762706256, 'accuracy': 0.2573051948051948, 'precision': 0.33629558934203313, 'recall': 0.2573051948051948, 'f1': 0.2733328865811727, 'macro_accuracy': 0.2573051948051948, 'macro_precision': 0.2562093684083374, 'macro_recall': 0.26693191059725563, 'macro_f1': 0.23998221696202066, 'question_accuracy': 0.22727272727272727, 'mean_confidence': 0.93157506}
2024-12-13 22:03:43,500 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 4, 'avg_loss': 1.4118953675639874, 'accuracy': 0.2727272727272727, 'precision': 0.354701622639765, 'recall': 0.2727272727272727, 'f1': 0.29529934448263, 'macro_accuracy': 0.2727272727272727, 'macro_precision': 0.2624655410366186, 'macro_recall': 0.25920088355445076, 'macro_f1': 0.24506807695292215, 'question_accuracy': 0.2564935064935065, 'mean_confidence': 0.96054614}
2024-12-13 22:05:20,601 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 5, 'avg_loss': 1.4206239947772235, 'accuracy': 0.26866883116883117, 'precision': 0.3450974365563406, 'recall': 0.26866883116883117, 'f1': 0.29163016330165087, 'macro_accuracy': 0.26866883116883117, 'macro_precision': 0.25030327179245915, 'macro_recall': 0.24513386360766343, 'macro_f1': 0.23463284358738906, 'question_accuracy': 0.2662337662337662, 'mean_confidence': 0.95496863}
2024-12-13 22:06:57,437 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 6, 'avg_loss': 1.4455987625149873, 'accuracy': 0.26704545454545453, 'precision': 0.3481836428837277, 'recall': 0.26704545454545453, 'f1': 0.28449534213638344, 'macro_accuracy': 0.26704545454545453, 'macro_precision': 0.2585873640518981, 'macro_recall': 0.270407484355481, 'macro_f1': 0.2426033083403193, 'question_accuracy': 0.2564935064935065, 'mean_confidence': 0.9273101}
2024-12-13 22:08:34,484 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 7, 'avg_loss': 1.4226055402449895, 'accuracy': 0.2637987012987013, 'precision': 0.34676783840336395, 'recall': 0.2637987012987013, 'f1': 0.2866823365874431, 'macro_accuracy': 0.2637987012987013, 'macro_precision': 0.25341888507122307, 'macro_recall': 0.2489220809204413, 'macro_f1': 0.2342301925660143, 'question_accuracy': 0.2662337662337662, 'mean_confidence': 0.96888864}
2024-12-13 22:10:11,547 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 8, 'avg_loss': 1.4535258021368578, 'accuracy': 0.2288961038961039, 'precision': 0.30666741129939246, 'recall': 0.2288961038961039, 'f1': 0.24874544435973237, 'macro_accuracy': 0.2288961038961039, 'macro_precision': 0.22579908517384456, 'macro_recall': 0.22189834596511093, 'macro_f1': 0.20857474203787166, 'question_accuracy': 0.237012987012987, 'mean_confidence': 0.9893941}
2024-12-13 22:11:48,597 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 9, 'avg_loss': 1.4423306898890014, 'accuracy': 0.2597402597402597, 'precision': 0.3420854329068981, 'recall': 0.2597402597402597, 'f1': 0.2813381063274427, 'macro_accuracy': 0.2597402597402597, 'macro_precision': 0.249835789231497, 'macro_recall': 0.24858373086386634, 'macro_f1': 0.2314195334831239, 'question_accuracy': 0.2792207792207792, 'mean_confidence': 0.9371986}

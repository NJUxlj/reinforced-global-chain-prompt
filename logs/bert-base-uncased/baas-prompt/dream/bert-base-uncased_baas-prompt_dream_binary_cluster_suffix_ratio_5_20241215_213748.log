2024-12-15 21:38:59,921 - bert-base-uncased_baas-prompt_dream_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 0, 'avg_loss': 1.1102216087710794, 'accuracy': 0.3630952380952381, 'precision': 0.4613893310885057, 'recall': 0.3630952380952381, 'f1': 0.39035322501290487, 'macro_accuracy': 0.3630952380952381, 'macro_precision': 0.3374766278311152, 'macro_recall': 0.344475879371158, 'macro_f1': 0.3200057588075881, 'question_accuracy': 0.36507936507936506, 'mean_confidence': 0.7122781}
2024-12-15 21:39:57,531 - bert-base-uncased_baas-prompt_dream_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 1, 'avg_loss': 1.1077220358773676, 'accuracy': 0.3492063492063492, 'precision': 0.44649122498276933, 'recall': 0.3492063492063492, 'f1': 0.3783357417204645, 'macro_accuracy': 0.3492063492063492, 'macro_precision': 0.3211889802118898, 'macro_recall': 0.31980448192730765, 'macro_f1': 0.3025584995050454, 'question_accuracy': 0.3333333333333333, 'mean_confidence': 0.6401909}
2024-12-15 21:40:54,954 - bert-base-uncased_baas-prompt_dream_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 2, 'avg_loss': 1.107619268419855, 'accuracy': 0.31547619047619047, 'precision': 0.46144044812405116, 'recall': 0.31547619047619047, 'f1': 0.3505492314995225, 'macro_accuracy': 0.31547619047619047, 'macro_precision': 0.3229839054350153, 'macro_recall': 0.3054262898778341, 'macro_f1': 0.2842637276897648, 'question_accuracy': 0.29365079365079366, 'mean_confidence': 0.2846467}
2024-12-15 21:41:52,453 - bert-base-uncased_baas-prompt_dream_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 3, 'avg_loss': 1.094394738449476, 'accuracy': 0.3353174603174603, 'precision': 0.46047161554680355, 'recall': 0.3353174603174603, 'f1': 0.3636222957651529, 'macro_accuracy': 0.3353174603174603, 'macro_precision': 0.3358193463456621, 'macro_recall': 0.33593382649115694, 'macro_f1': 0.3074726674726675, 'question_accuracy': 0.30952380952380953, 'mean_confidence': 0.44300112}
2024-12-15 21:42:49,866 - bert-base-uncased_baas-prompt_dream_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 4, 'avg_loss': 1.0979412207428698, 'accuracy': 0.3353174603174603, 'precision': 0.4536911594694613, 'recall': 0.3353174603174603, 'f1': 0.36480229540416553, 'macro_accuracy': 0.3353174603174603, 'macro_precision': 0.32759012475993604, 'macro_recall': 0.3237327720465811, 'macro_f1': 0.30154033907249816, 'question_accuracy': 0.31746031746031744, 'mean_confidence': 0.77900743}
2024-12-15 21:43:47,364 - bert-base-uncased_baas-prompt_dream_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 5, 'avg_loss': 1.0924361004879337, 'accuracy': 0.3392857142857143, 'precision': 0.4593464485705865, 'recall': 0.3392857142857143, 'f1': 0.3674157115564263, 'macro_accuracy': 0.3392857142857143, 'macro_precision': 0.3348806366047746, 'macro_recall': 0.3384727645643513, 'macro_f1': 0.30898208197144633, 'question_accuracy': 0.38095238095238093, 'mean_confidence': 0.5646407}
2024-12-15 21:44:44,813 - bert-base-uncased_baas-prompt_dream_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 6, 'avg_loss': 1.0952375181682448, 'accuracy': 0.35912698412698413, 'precision': 0.49091659254063075, 'recall': 0.35912698412698413, 'f1': 0.3898748894820136, 'macro_accuracy': 0.35912698412698413, 'macro_precision': 0.35756443139504795, 'macro_recall': 0.3554898171156602, 'macro_f1': 0.32780396950119317, 'question_accuracy': 0.36507936507936506, 'mean_confidence': 0.9049305}
2024-12-15 21:45:42,244 - bert-base-uncased_baas-prompt_dream_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 7, 'avg_loss': 1.1189245459921073, 'accuracy': 0.3472222222222222, 'precision': 0.4499181449038212, 'recall': 0.3472222222222222, 'f1': 0.37695022359741687, 'macro_accuracy': 0.3472222222222222, 'macro_precision': 0.3311310596998289, 'macro_recall': 0.325987361486119, 'macro_f1': 0.3102654690157865, 'question_accuracy': 0.373015873015873, 'mean_confidence': 0.8283377}
2024-12-15 21:46:40,015 - bert-base-uncased_baas-prompt_dream_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 8, 'avg_loss': 1.119104207498241, 'accuracy': 0.3392857142857143, 'precision': 0.4415734610157233, 'recall': 0.3392857142857143, 'f1': 0.3665035793119467, 'macro_accuracy': 0.3392857142857143, 'macro_precision': 0.3254575077827238, 'macro_recall': 0.32844155673406644, 'macro_f1': 0.30466192647935436, 'question_accuracy': 0.3412698412698413, 'mean_confidence': 0.19650859}
2024-12-15 21:47:37,579 - bert-base-uncased_baas-prompt_dream_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 9, 'avg_loss': 1.0776195240582471, 'accuracy': 0.32341269841269843, 'precision': 0.41715691899612894, 'recall': 0.32341269841269843, 'f1': 0.3459273963388878, 'macro_accuracy': 0.32341269841269843, 'macro_precision': 0.312843851682664, 'macro_recall': 0.32256310591418863, 'macro_f1': 0.29623858438853673, 'question_accuracy': 0.30952380952380953, 'mean_confidence': 0.23552631}

2024-12-13 23:00:04,297 - bert-base-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_10 - INFO - {'epoch': 0, 'avg_loss': 1.3569760515794649, 'accuracy': 0.4875, 'precision': 0.653949190787426, 'recall': 0.4875, 'f1': 0.5098902071246815, 'macro_accuracy': 0.4875, 'macro_precision': 0.4717145191409897, 'macro_recall': 0.5713512994098101, 'macro_f1': 0.4627022501515245, 'question_accuracy': 0.5166666666666667, 'mean_confidence': 0.82882446}
2024-12-13 23:01:56,790 - bert-base-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_10 - INFO - {'epoch': 1, 'avg_loss': 1.2412741220259405, 'accuracy': 0.5083333333333333, 'precision': 0.6772053130208562, 'recall': 0.5083333333333333, 'f1': 0.5231261872848741, 'macro_accuracy': 0.5083333333333333, 'macro_precision': 0.49781240393241855, 'macro_recall': 0.6246016837772157, 'macro_f1': 0.4924016400076591, 'question_accuracy': 0.5666666666666667, 'mean_confidence': 0.7214206}
2024-12-13 23:03:49,573 - bert-base-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_10 - INFO - {'epoch': 2, 'avg_loss': 1.213271480340224, 'accuracy': 0.575, 'precision': 0.7194057322980554, 'recall': 0.575, 'f1': 0.5885229957426396, 'macro_accuracy': 0.575, 'macro_precision': 0.5445342759599987, 'macro_recall': 0.6868878019143976, 'macro_f1': 0.5551789890268034, 'question_accuracy': 0.6833333333333333, 'mean_confidence': 0.9319668}
2024-12-13 23:05:42,572 - bert-base-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_10 - INFO - {'epoch': 3, 'avg_loss': 1.1494774738183389, 'accuracy': 0.5958333333333333, 'precision': 0.7308276168988115, 'recall': 0.5958333333333333, 'f1': 0.6149702120947389, 'macro_accuracy': 0.5958333333333333, 'macro_precision': 0.5540930884212633, 'macro_recall': 0.6783681743788127, 'macro_f1': 0.5657942632498544, 'question_accuracy': 0.7, 'mean_confidence': 0.83199066}
2024-12-13 23:07:35,281 - bert-base-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_10 - INFO - {'epoch': 4, 'avg_loss': 1.1645319684521183, 'accuracy': 0.5958333333333333, 'precision': 0.7417460907762632, 'recall': 0.5958333333333333, 'f1': 0.6068573282143203, 'macro_accuracy': 0.5958333333333333, 'macro_precision': 0.5660585628258041, 'macro_recall': 0.7201076848683232, 'macro_f1': 0.5802451151482168, 'question_accuracy': 0.7333333333333333, 'mean_confidence': 0.92263573}
2024-12-13 23:09:28,006 - bert-base-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_10 - INFO - {'epoch': 5, 'avg_loss': 1.1396393669503075, 'accuracy': 0.6, 'precision': 0.7381856221012302, 'recall': 0.6, 'f1': 0.6114902069011658, 'macro_accuracy': 0.6, 'macro_precision': 0.5668753005413623, 'macro_recall': 0.7175597009373605, 'macro_f1': 0.5830774248582468, 'question_accuracy': 0.7333333333333333, 'mean_confidence': 0.9494581}
2024-12-13 23:11:20,396 - bert-base-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_10 - INFO - {'epoch': 6, 'avg_loss': 1.1498560790832226, 'accuracy': 0.6375, 'precision': 0.7817307161964646, 'recall': 0.6375, 'f1': 0.653349114420543, 'macro_accuracy': 0.6375, 'macro_precision': 0.6022301853230744, 'macro_recall': 0.7525991295938104, 'macro_f1': 0.6156864772936201, 'question_accuracy': 0.7333333333333333, 'mean_confidence': 0.9308098}
2024-12-13 23:13:12,976 - bert-base-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_10 - INFO - {'epoch': 7, 'avg_loss': 1.1405570304000772, 'accuracy': 0.5916666666666667, 'precision': 0.7366892896907793, 'recall': 0.5916666666666667, 'f1': 0.6057759929051519, 'macro_accuracy': 0.5916666666666667, 'macro_precision': 0.5607244418937567, 'macro_recall': 0.70692140306502, 'macro_f1': 0.5718750854666514, 'question_accuracy': 0.7166666666666667, 'mean_confidence': 0.9635832}
2024-12-13 23:15:05,014 - bert-base-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_10 - INFO - {'epoch': 8, 'avg_loss': 1.1192135756814874, 'accuracy': 0.6083333333333333, 'precision': 0.767724117795957, 'recall': 0.6083333333333333, 'f1': 0.6246000109582032, 'macro_accuracy': 0.6083333333333333, 'macro_precision': 0.5797435366400884, 'macro_recall': 0.7238258195705004, 'macro_f1': 0.5871202017401316, 'question_accuracy': 0.7166666666666667, 'mean_confidence': 0.85391116}
2024-12-13 23:16:56,684 - bert-base-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_10 - INFO - {'epoch': 9, 'avg_loss': 1.1236085040228707, 'accuracy': 0.625, 'precision': 0.7550193002866071, 'recall': 0.625, 'f1': 0.6424195494770716, 'macro_accuracy': 0.625, 'macro_precision': 0.5784469732425819, 'macro_recall': 0.7166111813718197, 'macro_f1': 0.5952936444086886, 'question_accuracy': 0.7333333333333333, 'mean_confidence': 0.8962434}

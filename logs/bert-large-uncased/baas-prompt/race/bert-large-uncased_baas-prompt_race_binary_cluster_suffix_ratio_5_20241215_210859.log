2024-12-15 21:12:17,201 - bert-large-uncased_baas-prompt_race_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 0, 'avg_loss': 1.4125299099235424, 'accuracy': 0.24025974025974026, 'precision': 0.32187596589623585, 'recall': 0.24025974025974026, 'f1': 0.2600836698540752, 'macro_accuracy': 0.24025974025974026, 'macro_precision': 0.2342413487801783, 'macro_recall': 0.23328249929303, 'macro_f1': 0.21780041837696973, 'question_accuracy': 0.22727272727272727, 'mean_confidence': 0.14732164}
2024-12-15 21:15:25,245 - bert-large-uncased_baas-prompt_race_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 1, 'avg_loss': 1.6715108069751423, 'accuracy': 0.25162337662337664, 'precision': 0.3394201684301432, 'recall': 0.25162337662337664, 'f1': 0.2738913494523006, 'macro_accuracy': 0.25162337662337664, 'macro_precision': 0.24482547544036615, 'macro_recall': 0.24030630726522936, 'macro_f1': 0.22606822841632052, 'question_accuracy': 0.262987012987013, 'mean_confidence': 0.14712323}
2024-12-15 21:18:30,770 - bert-large-uncased_baas-prompt_race_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 2, 'avg_loss': 1.7286817248117818, 'accuracy': 0.26704545454545453, 'precision': 0.36071219180982844, 'recall': 0.26704545454545453, 'f1': 0.2931227376490711, 'macro_accuracy': 0.26704545454545453, 'macro_precision': 0.25319366216575767, 'macro_recall': 0.2449435434416617, 'macro_f1': 0.23279084600632538, 'question_accuracy': 0.29545454545454547, 'mean_confidence': 0.99952716}
2024-12-15 21:21:37,008 - bert-large-uncased_baas-prompt_race_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 3, 'avg_loss': 1.7164397275308827, 'accuracy': 0.2483766233766234, 'precision': 0.32096981590188917, 'recall': 0.2483766233766234, 'f1': 0.2667369128147119, 'macro_accuracy': 0.2483766233766234, 'macro_precision': 0.23538872691628202, 'macro_recall': 0.24024231133906176, 'macro_f1': 0.22174712139752878, 'question_accuracy': 0.2435064935064935, 'mean_confidence': 0.8824215}
2024-12-15 21:24:42,651 - bert-large-uncased_baas-prompt_race_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 4, 'avg_loss': 1.775062049443103, 'accuracy': 0.2694805194805195, 'precision': 0.33750036830785757, 'recall': 0.2694805194805195, 'f1': 0.28920726437787087, 'macro_accuracy': 0.2694805194805195, 'macro_precision': 0.2491467737643678, 'macro_recall': 0.2509168426850853, 'macro_f1': 0.23725109038216657, 'question_accuracy': 0.262987012987013, 'mean_confidence': 0.10905857}
2024-12-15 21:27:48,085 - bert-large-uncased_baas-prompt_race_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 5, 'avg_loss': 1.5470796567184237, 'accuracy': 0.26136363636363635, 'precision': 0.33805084780698014, 'recall': 0.26136363636363635, 'f1': 0.28238994674866985, 'macro_accuracy': 0.26136363636363635, 'macro_precision': 0.25296336902942446, 'macro_recall': 0.24991828045408276, 'macro_f1': 0.23736978478673418, 'question_accuracy': 0.2694805194805195, 'mean_confidence': 0.4951491}

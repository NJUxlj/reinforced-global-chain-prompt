2024-12-13 03:53:00,691 - bert-large-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 0, 'avg_loss': 1.1170045852661132, 'accuracy': 0.36088709677419356, 'precision': 0.522039958655917, 'recall': 0.36088709677419356, 'f1': 0.4003405953011188, 'macro_accuracy': 0.36088709677419356, 'macro_precision': 0.35942639506030355, 'macro_recall': 0.35552796113543783, 'macro_f1': 0.321697273766604, 'question_accuracy': 0.4032258064516129, 'mean_confidence': 0.41845223}
2024-12-13 03:55:10,659 - bert-large-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 1, 'avg_loss': 1.1933203402318453, 'accuracy': 0.3588709677419355, 'precision': 0.5376868655676438, 'recall': 0.3588709677419355, 'f1': 0.3996603074723692, 'macro_accuracy': 0.3588709677419355, 'macro_precision': 0.36675939562537496, 'macro_recall': 0.3671829727904494, 'macro_f1': 0.32147009120922165, 'question_accuracy': 0.3951612903225806, 'mean_confidence': 0.49418345}
2024-12-13 03:57:20,933 - bert-large-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 2, 'avg_loss': 1.5866310725086614, 'accuracy': 0.3326612903225806, 'precision': 0.49584218321200274, 'recall': 0.3326612903225806, 'f1': 0.36350363972186, 'macro_accuracy': 0.3326612903225806, 'macro_precision': 0.3454257790095793, 'macro_recall': 0.35315338866740736, 'macro_f1': 0.30610867475274256, 'question_accuracy': 0.3225806451612903, 'mean_confidence': 0.941227}
2024-12-13 03:59:30,530 - bert-large-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 3, 'avg_loss': 1.4771133353835657, 'accuracy': 0.3225806451612903, 'precision': 0.4626571701611921, 'recall': 0.3225806451612903, 'f1': 0.35587841304012113, 'macro_accuracy': 0.3225806451612903, 'macro_precision': 0.31864977875208056, 'macro_recall': 0.3218547807332854, 'macro_f1': 0.2875151191961756, 'question_accuracy': 0.3064516129032258, 'mean_confidence': 0.5572649}
2024-12-13 04:01:40,541 - bert-large-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 4, 'avg_loss': 1.283657171224293, 'accuracy': 0.3346774193548387, 'precision': 0.4820502529553196, 'recall': 0.3346774193548387, 'f1': 0.37316505432874303, 'macro_accuracy': 0.3346774193548387, 'macro_precision': 0.3250621118012422, 'macro_recall': 0.3179138618390955, 'macro_f1': 0.29120585291874423, 'question_accuracy': 0.3629032258064516, 'mean_confidence': 0.83534884}
2024-12-13 04:03:50,019 - bert-large-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 5, 'avg_loss': 1.297532129915137, 'accuracy': 0.33064516129032256, 'precision': 0.469834598611969, 'recall': 0.33064516129032256, 'f1': 0.36584793174285324, 'macro_accuracy': 0.33064516129032256, 'macro_precision': 0.32417444743366564, 'macro_recall': 0.3261144877967308, 'macro_f1': 0.2926626977226873, 'question_accuracy': 0.3709677419354839, 'mean_confidence': 0.47979742}
2024-12-13 04:06:00,106 - bert-large-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 6, 'avg_loss': 1.5435039921810751, 'accuracy': 0.3407258064516129, 'precision': 0.4723436903212859, 'recall': 0.3407258064516129, 'f1': 0.3736709529788579, 'macro_accuracy': 0.3407258064516129, 'macro_precision': 0.32838428434454925, 'macro_recall': 0.33738826075274675, 'macro_f1': 0.3016680615114931, 'question_accuracy': 0.3790322580645161, 'mean_confidence': 0.756553}
2024-12-13 04:08:09,524 - bert-large-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 7, 'avg_loss': 1.9816791035627064, 'accuracy': 0.3649193548387097, 'precision': 0.49576672748520284, 'recall': 0.3649193548387097, 'f1': 0.402067566389899, 'macro_accuracy': 0.3649193548387097, 'macro_precision': 0.3407537750593103, 'macro_recall': 0.3372619073553653, 'macro_f1': 0.314231970034503, 'question_accuracy': 0.4274193548387097, 'mean_confidence': 0.66184396}
2024-12-13 04:10:20,044 - bert-large-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 8, 'avg_loss': 1.927252517248455, 'accuracy': 0.36088709677419356, 'precision': 0.5045429080772222, 'recall': 0.36088709677419356, 'f1': 0.3957805521001118, 'macro_accuracy': 0.36088709677419356, 'macro_precision': 0.3528818864221108, 'macro_recall': 0.36402559019381453, 'macro_f1': 0.3222924493461186, 'question_accuracy': 0.4032258064516129, 'mean_confidence': 0.9958864}
2024-12-13 04:12:29,586 - bert-large-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 9, 'avg_loss': 1.5759371126952924, 'accuracy': 0.3467741935483871, 'precision': 0.5073194703683171, 'recall': 0.3467741935483871, 'f1': 0.38306600262098256, 'macro_accuracy': 0.3467741935483871, 'macro_precision': 0.3495820594572882, 'macro_recall': 0.35035691203915503, 'macro_f1': 0.31193272799112215, 'question_accuracy': 0.33064516129032256, 'mean_confidence': 0.99116683}

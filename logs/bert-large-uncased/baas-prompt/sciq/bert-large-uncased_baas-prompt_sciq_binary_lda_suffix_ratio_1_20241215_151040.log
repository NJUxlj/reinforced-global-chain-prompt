2024-12-15 15:15:29,523 - bert-large-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_1 - INFO - {'epoch': 0, 'avg_loss': 1.3298667236597823, 'accuracy': 0.45564516129032256, 'precision': 0.6202358915343315, 'recall': 0.45564516129032256, 'f1': 0.47138052625995636, 'macro_accuracy': 0.45564516129032256, 'macro_precision': 0.45560020351562935, 'macro_recall': 0.5380044813024514, 'macro_f1': 0.43849342285557685, 'question_accuracy': 0.5161290322580645, 'mean_confidence': 0.63857025}
2024-12-15 15:20:10,516 - bert-large-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_1 - INFO - {'epoch': 1, 'avg_loss': 1.3338704852946646, 'accuracy': 0.43548387096774194, 'precision': 0.6091216181573321, 'recall': 0.43548387096774194, 'f1': 0.4474450656675058, 'macro_accuracy': 0.43548387096774194, 'macro_precision': 0.446605083103751, 'macro_recall': 0.5363773761905383, 'macro_f1': 0.42533424077434967, 'question_accuracy': 0.5483870967741935, 'mean_confidence': 0.94553477}
2024-12-15 15:24:49,642 - bert-large-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_1 - INFO - {'epoch': 2, 'avg_loss': 1.54330956772969, 'accuracy': 0.4838709677419355, 'precision': 0.6463873047213811, 'recall': 0.4838709677419355, 'f1': 0.4955063317274267, 'macro_accuracy': 0.4838709677419355, 'macro_precision': 0.486986959771796, 'macro_recall': 0.583365001397014, 'macro_f1': 0.47439337997888037, 'question_accuracy': 0.5806451612903226, 'mean_confidence': 0.99524504}
2024-12-15 15:29:28,740 - bert-large-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_1 - INFO - {'epoch': 3, 'avg_loss': 1.4117144010852447, 'accuracy': 0.3709677419354839, 'precision': 0.49595431687410957, 'recall': 0.3709677419354839, 'f1': 0.3760689436552678, 'macro_accuracy': 0.3709677419354839, 'macro_precision': 0.3767609447345447, 'macro_recall': 0.47093867036115344, 'macro_f1': 0.36685052196922324, 'question_accuracy': 0.45161290322580644, 'mean_confidence': 0.995202}
2024-12-15 15:34:07,478 - bert-large-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_1 - INFO - {'epoch': 4, 'avg_loss': 1.4031812016887497, 'accuracy': 0.4879032258064516, 'precision': 0.6234119443414493, 'recall': 0.4879032258064516, 'f1': 0.5054315627092233, 'macro_accuracy': 0.4879032258064516, 'macro_precision': 0.4685205140485313, 'macro_recall': 0.5506813881541899, 'macro_f1': 0.46499453817210823, 'question_accuracy': 0.5645161290322581, 'mean_confidence': 0.99140257}
2024-12-15 15:38:47,509 - bert-large-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_1 - INFO - {'epoch': 5, 'avg_loss': 1.5879511460879105, 'accuracy': 0.39919354838709675, 'precision': 0.5850348576155029, 'recall': 0.39919354838709675, 'f1': 0.42301902691776566, 'macro_accuracy': 0.39919354838709675, 'macro_precision': 0.4043192918192918, 'macro_recall': 0.46311132030129176, 'macro_f1': 0.37648513683144014, 'question_accuracy': 0.4032258064516129, 'mean_confidence': 0.23351431}
2024-12-15 15:43:26,370 - bert-large-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_1 - INFO - {'epoch': 6, 'avg_loss': 1.4990452654420807, 'accuracy': 0.47580645161290325, 'precision': 0.6441036565735813, 'recall': 0.47580645161290325, 'f1': 0.49210544990323524, 'macro_accuracy': 0.47580645161290325, 'macro_precision': 0.4732050768875639, 'macro_recall': 0.5577592908670028, 'macro_f1': 0.4595259583493152, 'question_accuracy': 0.5967741935483871, 'mean_confidence': 0.99972063}
2024-12-15 15:48:07,527 - bert-large-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_1 - INFO - {'epoch': 7, 'avg_loss': 1.679328670540591, 'accuracy': 0.4717741935483871, 'precision': 0.6292670477328067, 'recall': 0.4717741935483871, 'f1': 0.48955721693625326, 'macro_accuracy': 0.4717741935483871, 'macro_precision': 0.46822091842583646, 'macro_recall': 0.553114671687231, 'macro_f1': 0.4551777981302053, 'question_accuracy': 0.4838709677419355, 'mean_confidence': 0.90868044}
2024-12-15 15:52:47,617 - bert-large-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_1 - INFO - {'epoch': 8, 'avg_loss': 1.8883365283967282, 'accuracy': 0.45564516129032256, 'precision': 0.6108870967741935, 'recall': 0.45564516129032256, 'f1': 0.47035346556064733, 'macro_accuracy': 0.45564516129032256, 'macro_precision': 0.4544871794871795, 'macro_recall': 0.5461309588438226, 'macro_f1': 0.44114902219122165, 'question_accuracy': 0.5645161290322581, 'mean_confidence': 0.24693024}
2024-12-15 15:57:26,924 - bert-large-uncased_baas-prompt_sciq_binary_lda_suffix_ratio_1 - INFO - {'epoch': 9, 'avg_loss': 1.7337195955151719, 'accuracy': 0.42338709677419356, 'precision': 0.6154558161896914, 'recall': 0.42338709677419356, 'f1': 0.4346724617427123, 'macro_accuracy': 0.42338709677419356, 'macro_precision': 0.4419059364195969, 'macro_recall': 0.5284878662456804, 'macro_f1': 0.4140552320523796, 'question_accuracy': 0.46774193548387094, 'mean_confidence': 0.010015583}

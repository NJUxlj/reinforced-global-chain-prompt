import random
from sentence_transformers import SentenceTransformer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import numpy as np
import json
import matplotlib.pyplot as plt
import argparse
from autocot_utils import (
    fix_seed,
    Arguments
)


from typing import List, Tuple, Dict


'''

python run_autocot_demo.py \
--task race \
--pred_file cot_log/race_zero_shot_cot.log \
--demo_save_dir demos/race \
--max_ra_len 20


python run_autocot_demo.py \
--task sciq \
--pred_file cot_log/sciq_zero_shot_cot.log \
--demo_save_dir demos/sciq \
--max_ra_len 20


'''


def parse_arguments():
    parser = argparse.ArgumentParser(description="Zero-shot-CoT")
    parser.add_argument(
        "--task", type=str, default="race",
        choices=["race", "dream", "sciq", "commonsense_qa", ], help="dataset used for experiment, select from [race, dream, sciq, commonsense_qa ]"
    )
    parser.add_argument( # criterion, how many reasoning steps
        "--max_ra_len", type=int, default=5, help="maximum number of reasoning chains"
    )
    parser.add_argument( # model's CoT reasoning results (steps)
        "--pred_file", type=str, default="cot_log/race_zero_shot_cot.log",
        help="use the reasoning chains generated by zero-shot-cot."
    )
    parser.add_argument( # where to save the contructed demonstrations of the prompt
        "--demo_save_dir", type=str, default="demos/race", help="where to save the contructed demonstrations"
    )
    parser.add_argument("--random_seed", type=int, default=42, help="random seed")
    
    parser.add_argument(
        "--encoder", type=str, default="all-MiniLM-L6-v2", help="which sentence-transformer encoder for clustering"
    )
    parser.add_argument( # 哪个样本离质心近，就先挑哪一个
        "--sampling", type=str, default="center", help="whether to sample the cluster center first"
    )
    parser.add_argument(
        "--debug", type=bool, default=True, help="debug mode"
    )
    args = parser.parse_args()
    return args





def main():
    args = parse_arguments()
    fix_seed(args.random_seed)
    encoder = SentenceTransformer(args.encoder) # 传入模型名
    
    
    task = args.task
    pred_file = args.pred_file
    save_file = args.demo_save_dir
    
    # max reasoning step length
    max_ra_len = args.max_ra_len
    
    # this will be set to the number of class labels later
    num_clusters = 8
    
    corpus = []
    question = []
    rationale = []
    gold_ans = []
    pred_ans = []
    
    
    with open(pred_file, "r", encoding="utf-8") as fp:
        answer_seg = ""
        for line in fp:
            if "Q: " in line:
                c_question = line.strip()
            if "A: " in line and "step by step" in line:
                answer_seg = line # 初始化为 A: Let's think step by step.
            elif "Therefore" in line and "the answer" in line:
                c_rationale = answer_seg # 检测到推理链结束，准备接收推理链

            elif answer_seg != "":
                answer_seg += line  # 拼接推理步骤
            if "pred_mode" in line: # 预测标签
                c_pred_ans = line.split(":")[1].strip()
            if "GT :" in line: # 真实标签，是当前demo的最后一行
                c_gold_ans = line.split(":")[1].strip()

                c_rationale = c_rationale.replace("A: Let's think step by step.", "Let's think step by step.")
                c_question = c_question + "\nA:"

                corpus.append(c_question)
                question.append(c_question)
                rationale.append(c_rationale)
                pred_ans.append(c_pred_ans)
                if args.debug:
                    gold_ans.append(c_gold_ans)
                answer_seg = ""

    corpus_embeddings = encoder.encode(corpus)
    
    # Perform kmean clustering
    clustering_model = KMeans(n_clusters=num_clusters, random_state=args.random_seed)
    clustering_model.fit(corpus_embeddings)
    # 返回一个数组，表示每个样本所属的聚类标签。
    cluster_assignment = clustering_model.labels_
    
    clustered_sentences = [[] for i in range(num_clusters)]
    # dict{sentence_id: {cluster_id: sentence-cluster-distance}}
    dist = clustering_model.transform(corpus_embeddings)
    # List[List[distance1, distance2,...], List[]]
    clustered_dists = [[] for i in range(num_clusters)]
    # List[List[sentence_id1, sentence_id2,...], List[]]
    clustered_idx = [[] for i in range(num_clusters)]
    
    for sentence_id, cluster_id in enumerate(cluster_assignment):
        clustered_sentences[cluster_id].append(corpus[sentence_id])
        clustered_dists[cluster_id].append(dist[sentence_id][cluster_id])
        clustered_idx[cluster_id].append(sentence_id)

    demos = []
    
    for i in range(len(clustered_dists)):
        print("Cluster ", i+1)
        # 把一个cluster中的sentence_id对应的下标，和一组句子到聚类中心的距离，封装成一个元组列表
            # 注意：range(len(clustered_dists[i])产生的下标序列，不等于 cluster_i 的sentence_id数组
            # 例如:
                # clustered_dists[i] = [101, 201, 122, 56, 90]
                # range(len(clustered_dists[i]) = [0, 1, 2, 3, 4]
                
        # map: 把list()函数映射到 zip返回的迭代器上
        tmp = list(map(list, zip(range(len(clustered_dists[i])), clustered_dists[i])))
        # 把当前cluster中所有的question-cluster距离，按照离聚类中心从小到大进行排序
        # [(3, 999), (1, 203), (2, 124), (0, 99), (4, 55)]
        top_min_dist = sorted(tmp, key=lambda x: x[1], reverse=False)
        if not args.sampling == "center":
            random.shuffle(top_min_dist)
            
        for element in top_min_dist: # for each question q_j^(i) in q^(i)
            min_idx = element[0] # 取出离cluster的最短距离对应(sentence_id)的下标 id
            # clustered_idx[i][min_idx] 取到 min_idx对应的sentence_id
            c_rationale = rationale[clustered_idx[i][min_idx]].strip() # r_j^(i)
            c_pred_ans = pred_ans[clustered_idx[i][min_idx]].strip() # a_j^(i)

            # if satisfy the criterion   # 原论文中的criteron已经不适用了
            # if len(question[clustered_idx[i][min_idx]].strip().split()) <= 60 \
            if len(c_rationale.replace("\n\n", "\n").split("\n")) <= max_ra_len and c_pred_ans != "":
                if not args.task in ["race", "dream", "sciq", "commonsense_qa"]:
                    continue
                    # 如果预测的答案既不在倒数第二句话中，也不在最后十句话中
                    # if not (c_pred_ans.strip() in c_rationale.split()[-10:]):
                    #     continue
                c_question = question[clustered_idx[i][min_idx]]
                c_rationale = c_rationale.replace("\n\n", "\n").replace("\n", " ").strip()
                c_rationale = " ".join(c_rationale.split())
                if args.debug:
                    c_gold_ans = gold_ans[clustered_idx[i][min_idx]]
                else:
                    c_gold_ans = None
                demo_element = {
                    "question": c_question,
                    "rationale": c_rationale,
                    "pred_ans": c_pred_ans,
                    "gold_ans": c_gold_ans,
                }
                demos.append(demo_element)
                print(c_question)
                print(c_rationale)
                print(c_pred_ans)
                print(c_gold_ans)
                print("")
                break

    demos:Dict[List[Dict]] = {"demo": demos}

    with open(args.demo_save_dir, 'w', encoding="utf-8") as write_f:
        json.dump(demos, write_f, indent=4, ensure_ascii=False)



if __name__ == '__main__':
    main()
2024-12-15 13:20:22,067 - bert-large-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 0, 'avg_loss': 1.6578672951773594, 'accuracy': 0.18571428571428572, 'precision': 0.283437909071203, 'recall': 0.18571428571428572, 'f1': 0.20933838854878134, 'macro_accuracy': 0.18571428571428572, 'macro_precision': 0.1804199076403873, 'macro_recall': 0.1734974622819143, 'macro_f1': 0.15966866454904818, 'question_accuracy': 0.18571428571428572, 'mean_confidence': 0.13694546}
2024-12-15 13:25:44,590 - bert-large-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 1, 'avg_loss': 2.045192753798083, 'accuracy': 0.18571428571428572, 'precision': 0.3061022507470126, 'recall': 0.18571428571428572, 'f1': 0.207516468102682, 'macro_accuracy': 0.18571428571428572, 'macro_precision': 0.19615336592104565, 'macro_recall': 0.1836564815343769, 'macro_f1': 0.16735474531671782, 'question_accuracy': 0.14285714285714285, 'mean_confidence': 0.86202514}
2024-12-15 13:31:05,248 - bert-large-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 2, 'avg_loss': 2.1509666698494634, 'accuracy': 0.21428571428571427, 'precision': 0.3096084501118201, 'recall': 0.21428571428571427, 'f1': 0.23296475277002093, 'macro_accuracy': 0.21428571428571427, 'macro_precision': 0.2106181223797506, 'macro_recall': 0.21842367502300136, 'macro_f1': 0.19352892192489196, 'question_accuracy': 0.18571428571428572, 'mean_confidence': 0.34110332}
2024-12-15 13:36:28,623 - bert-large-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 3, 'avg_loss': 1.8304275693862062, 'accuracy': 0.12857142857142856, 'precision': 0.22195323110304727, 'recall': 0.12857142857142856, 'f1': 0.14875569502283756, 'macro_accuracy': 0.12857142857142856, 'macro_precision': 0.13239911368587837, 'macro_recall': 0.11500263622560525, 'macro_f1': 0.1091363899499562, 'question_accuracy': 0.1, 'mean_confidence': 0.9934758}
2024-12-15 13:41:50,221 - bert-large-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 4, 'avg_loss': 1.9591179901832028, 'accuracy': 0.20714285714285716, 'precision': 0.33587857676281835, 'recall': 0.20714285714285716, 'f1': 0.23659048395587143, 'macro_accuracy': 0.20714285714285716, 'macro_precision': 0.20812070724601095, 'macro_recall': 0.18728624559971263, 'macro_f1': 0.1779986271838156, 'question_accuracy': 0.18571428571428572, 'mean_confidence': 0.9969364}
2024-12-15 13:47:10,857 - bert-large-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 5, 'avg_loss': 2.0751807787700702, 'accuracy': 0.175, 'precision': 0.2616751811781042, 'recall': 0.175, 'f1': 0.19502277397537335, 'macro_accuracy': 0.175, 'macro_precision': 0.16828983465689984, 'macro_recall': 0.1676109686597167, 'macro_f1': 0.15183067858471963, 'question_accuracy': 0.17142857142857143, 'mean_confidence': 0.009295715}
2024-12-15 13:52:34,464 - bert-large-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 6, 'avg_loss': 2.4028870511407914, 'accuracy': 0.19642857142857142, 'precision': 0.3104854856922526, 'recall': 0.19642857142857142, 'f1': 0.22831557523684776, 'macro_accuracy': 0.19642857142857142, 'macro_precision': 0.17879506458453825, 'macro_recall': 0.15563366782759874, 'macro_f1': 0.15278891027758168, 'question_accuracy': 0.17142857142857143, 'mean_confidence': 0.8862603}
2024-12-15 13:57:56,245 - bert-large-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 7, 'avg_loss': 2.504274022128237, 'accuracy': 0.23214285714285715, 'precision': 0.32024894957983197, 'recall': 0.23214285714285715, 'f1': 0.2484172143055147, 'macro_accuracy': 0.23214285714285715, 'macro_precision': 0.23406617647058825, 'macro_recall': 0.2456751831930629, 'macro_f1': 0.2152855590084767, 'question_accuracy': 0.14285714285714285, 'mean_confidence': 0.9995139}
2024-12-15 14:03:17,634 - bert-large-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 8, 'avg_loss': 2.787958013138881, 'accuracy': 0.19285714285714287, 'precision': 0.32610271230315646, 'recall': 0.19285714285714287, 'f1': 0.21310177606326125, 'macro_accuracy': 0.19285714285714287, 'macro_precision': 0.20554665986984402, 'macro_recall': 0.20018002951075334, 'macro_f1': 0.172655318985248, 'question_accuracy': 0.11428571428571428, 'mean_confidence': 0.9221577}
2024-12-15 14:08:42,325 - bert-large-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 9, 'avg_loss': 2.820175140900047, 'accuracy': 0.21428571428571427, 'precision': 0.3173354048131296, 'recall': 0.21428571428571427, 'f1': 0.23609951172933924, 'macro_accuracy': 0.21428571428571427, 'macro_precision': 0.20933638849533276, 'macro_recall': 0.20929781187171445, 'macro_f1': 0.18946049511592128, 'question_accuracy': 0.21428571428571427, 'mean_confidence': 0.62718296}

2024-12-15 02:06:12,358 - bert-large-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_10 - INFO - {'epoch': 0, 'avg_loss': 1.6557140769927126, 'accuracy': 0.19285714285714287, 'precision': 0.3594522829986016, 'recall': 0.19285714285714287, 'f1': 0.22346071063124098, 'macro_accuracy': 0.19285714285714287, 'macro_precision': 0.20031947794013333, 'macro_recall': 0.1921949221949222, 'macro_f1': 0.1653637251096762, 'question_accuracy': 0.17142857142857143, 'mean_confidence': 0.99993974}
2024-12-15 02:09:20,720 - bert-large-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_10 - INFO - {'epoch': 1, 'avg_loss': 1.7690238794802051, 'accuracy': 0.18928571428571428, 'precision': 0.32264355557553454, 'recall': 0.18928571428571428, 'f1': 0.21188065211293053, 'macro_accuracy': 0.18928571428571428, 'macro_precision': 0.19503255071790343, 'macro_recall': 0.19361998361998362, 'macro_f1': 0.1693997459906405, 'question_accuracy': 0.22857142857142856, 'mean_confidence': 0.0040295743}
2024-12-15 02:12:28,772 - bert-large-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_10 - INFO - {'epoch': 2, 'avg_loss': 1.7649590414213507, 'accuracy': 0.16785714285714284, 'precision': 0.3082010612338481, 'recall': 0.16785714285714284, 'f1': 0.184297988931479, 'macro_accuracy': 0.16785714285714284, 'macro_precision': 0.1834701364209561, 'macro_recall': 0.18625716625716623, 'macro_f1': 0.1546636659027743, 'question_accuracy': 0.11428571428571428, 'mean_confidence': 1.3608038e-09}
2024-12-15 02:15:37,187 - bert-large-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_10 - INFO - {'epoch': 3, 'avg_loss': 1.9090014021647603, 'accuracy': 0.175, 'precision': 0.292276003530118, 'recall': 0.175, 'f1': 0.19949064684655685, 'macro_accuracy': 0.175, 'macro_precision': 0.17016909309939532, 'macro_recall': 0.1692014742014742, 'macro_f1': 0.14827346094844263, 'question_accuracy': 0.17142857142857143, 'mean_confidence': 4.340264e-08}
2024-12-15 02:18:45,927 - bert-large-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_10 - INFO - {'epoch': 4, 'avg_loss': 2.023740449234059, 'accuracy': 0.18571428571428572, 'precision': 0.300028480973976, 'recall': 0.18571428571428572, 'f1': 0.2095088003531736, 'macro_accuracy': 0.18571428571428572, 'macro_precision': 0.1810434671001968, 'macro_recall': 0.17557739557739557, 'macro_f1': 0.15991915840897047, 'question_accuracy': 0.17142857142857143, 'mean_confidence': 0.00013848043}
2024-12-15 02:21:53,232 - bert-large-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_10 - INFO - {'epoch': 5, 'avg_loss': 2.1219968955571713, 'accuracy': 0.18214285714285713, 'precision': 0.37839049508692363, 'recall': 0.18214285714285713, 'f1': 0.21424244576655252, 'macro_accuracy': 0.18214285714285713, 'macro_precision': 0.20457010582010585, 'macro_recall': 0.1801105651105651, 'macro_f1': 0.15885819771411977, 'question_accuracy': 0.05714285714285714, 'mean_confidence': 0.0044056852}
2024-12-15 02:25:00,805 - bert-large-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_10 - INFO - {'epoch': 6, 'avg_loss': 2.172175501718333, 'accuracy': 0.14285714285714285, 'precision': 0.26587222777818165, 'recall': 0.14285714285714285, 'f1': 0.1617955112440162, 'macro_accuracy': 0.14285714285714285, 'macro_precision': 0.15858431097479908, 'macro_recall': 0.15037264537264539, 'macro_f1': 0.12990949102577007, 'question_accuracy': 0.11428571428571428, 'mean_confidence': 0.00039141756}
2024-12-15 02:28:07,812 - bert-large-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_10 - INFO - {'epoch': 7, 'avg_loss': 2.350091204929509, 'accuracy': 0.2, 'precision': 0.35823498468101356, 'recall': 0.2, 'f1': 0.23737993227255783, 'macro_accuracy': 0.2, 'macro_precision': 0.19416086267998983, 'macro_recall': 0.1691154791154791, 'macro_f1': 0.16117845166284744, 'question_accuracy': 0.1, 'mean_confidence': 0.9990028}
2024-12-15 02:31:15,356 - bert-large-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_10 - INFO - {'epoch': 8, 'avg_loss': 2.652553812992808, 'accuracy': 0.5107142857142857, 'precision': 0.3352211516576891, 'recall': 0.5107142857142857, 'f1': 0.3701071533911144, 'macro_accuracy': 0.5107142857142857, 'macro_precision': 0.1834041423260754, 'macro_recall': 0.2000859950859951, 'macro_f1': 0.15218584490696213, 'question_accuracy': 0.4714285714285714, 'mean_confidence': 0.9999999}
2024-12-15 02:34:23,034 - bert-large-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_10 - INFO - {'epoch': 9, 'avg_loss': 2.842817538613944, 'accuracy': 0.25, 'precision': 0.3883675464320625, 'recall': 0.25, 'f1': 0.2707178760347159, 'macro_accuracy': 0.25, 'macro_precision': 0.24272920567070377, 'macro_recall': 0.27063063063063064, 'macro_f1': 0.22418380531385465, 'question_accuracy': 0.3, 'mean_confidence': 0.96770936}

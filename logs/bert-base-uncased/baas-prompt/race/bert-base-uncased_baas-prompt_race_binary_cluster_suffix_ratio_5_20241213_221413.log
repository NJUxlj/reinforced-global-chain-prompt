2024-12-13 22:16:23,944 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 0, 'avg_loss': 1.4294885935658268, 'accuracy': 0.25487012987012986, 'precision': 0.3495745642048295, 'recall': 0.25487012987012986, 'f1': 0.27167219492491024, 'macro_accuracy': 0.25487012987012986, 'macro_precision': 0.26020353697653553, 'macro_recall': 0.26794133418555305, 'macro_f1': 0.239867738149424, 'question_accuracy': 0.24675324675324675, 'mean_confidence': 0.8250583}
2024-12-13 22:18:13,551 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 1, 'avg_loss': 1.4129411281024054, 'accuracy': 0.25162337662337664, 'precision': 0.3399540545407891, 'recall': 0.25162337662337664, 'f1': 0.2731132818300838, 'macro_accuracy': 0.25162337662337664, 'macro_precision': 0.24894245915286173, 'macro_recall': 0.24533748540446182, 'macro_f1': 0.22936387407099262, 'question_accuracy': 0.22727272727272727, 'mean_confidence': 0.72750866}
2024-12-13 22:20:03,560 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 2, 'avg_loss': 1.4071912678615692, 'accuracy': 0.25162337662337664, 'precision': 0.33737020407476853, 'recall': 0.25162337662337664, 'f1': 0.27313935875062584, 'macro_accuracy': 0.25162337662337664, 'macro_precision': 0.24623950714720216, 'macro_recall': 0.2443099609642103, 'macro_f1': 0.2261632688604935, 'question_accuracy': 0.2435064935064935, 'mean_confidence': 0.7595034}
2024-12-13 22:21:54,451 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 3, 'avg_loss': 1.392311466678586, 'accuracy': 0.26055194805194803, 'precision': 0.35247066151139567, 'recall': 0.26055194805194803, 'f1': 0.2815133438326096, 'macro_accuracy': 0.26055194805194803, 'macro_precision': 0.2580399775112939, 'macro_recall': 0.25926653692458107, 'macro_f1': 0.23767373148944337, 'question_accuracy': 0.22727272727272727, 'mean_confidence': 0.7312479}
2024-12-13 22:23:44,448 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 4, 'avg_loss': 1.4086346146664188, 'accuracy': 0.2727272727272727, 'precision': 0.3593320171337648, 'recall': 0.2727272727272727, 'f1': 0.2932785626299854, 'macro_accuracy': 0.2727272727272727, 'macro_precision': 0.26713956167388064, 'macro_recall': 0.27071153365565814, 'macro_f1': 0.24916329815389932, 'question_accuracy': 0.2435064935064935, 'mean_confidence': 0.83581936}
2024-12-13 22:25:34,375 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 5, 'avg_loss': 1.4060020033194094, 'accuracy': 0.25405844155844154, 'precision': 0.3371709478729351, 'recall': 0.25405844155844154, 'f1': 0.27288364946300286, 'macro_accuracy': 0.25405844155844154, 'macro_precision': 0.2514419511083547, 'macro_recall': 0.25577079954454934, 'macro_f1': 0.23377486832500147, 'question_accuracy': 0.2564935064935065, 'mean_confidence': 0.8329076}
2024-12-13 22:27:24,761 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 6, 'avg_loss': 1.4140444145953341, 'accuracy': 0.26055194805194803, 'precision': 0.3492373946111914, 'recall': 0.26055194805194803, 'f1': 0.28167333438018877, 'macro_accuracy': 0.26055194805194803, 'macro_precision': 0.257941577589606, 'macro_recall': 0.2573915126093792, 'macro_f1': 0.23873584640432693, 'question_accuracy': 0.237012987012987, 'mean_confidence': 0.76516753}
2024-12-13 22:29:15,346 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 7, 'avg_loss': 1.4006275366068581, 'accuracy': 0.25405844155844154, 'precision': 0.3391878787641244, 'recall': 0.25405844155844154, 'f1': 0.27349989738126074, 'macro_accuracy': 0.25405844155844154, 'macro_precision': 0.24756064739328565, 'macro_recall': 0.25251612165311127, 'macro_f1': 0.22989790797075513, 'question_accuracy': 0.23376623376623376, 'mean_confidence': 0.95072323}
2024-12-13 22:31:06,038 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 8, 'avg_loss': 1.4187669427332308, 'accuracy': 0.25162337662337664, 'precision': 0.32895067293688607, 'recall': 0.25162337662337664, 'f1': 0.26808450425515196, 'macro_accuracy': 0.25162337662337664, 'macro_precision': 0.24889396519856782, 'macro_recall': 0.25714451033478203, 'macro_f1': 0.23382581807539168, 'question_accuracy': 0.2305194805194805, 'mean_confidence': 0.81974626}
2024-12-13 22:32:56,577 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 9, 'avg_loss': 1.4179653096129525, 'accuracy': 0.2483766233766234, 'precision': 0.32888973816866, 'recall': 0.2483766233766234, 'f1': 0.2695785257469678, 'macro_accuracy': 0.2483766233766234, 'macro_precision': 0.23795572087653408, 'macro_recall': 0.23627184068717672, 'macro_f1': 0.22062590794395878, 'question_accuracy': 0.21753246753246752, 'mean_confidence': 0.9906582}

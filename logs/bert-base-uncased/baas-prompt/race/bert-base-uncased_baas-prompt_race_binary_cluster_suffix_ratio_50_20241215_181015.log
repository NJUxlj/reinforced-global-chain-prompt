2024-12-15 18:17:09,562 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 0, 'avg_loss': 1.42562856948758, 'accuracy': 0.2662337662337662, 'precision': 0.33894527404654357, 'recall': 0.2662337662337662, 'f1': 0.28655767158313156, 'macro_accuracy': 0.2662337662337662, 'macro_precision': 0.24716074100859545, 'macro_recall': 0.24919239208109328, 'macro_f1': 0.2341943894191458, 'question_accuracy': 0.29545454545454547, 'mean_confidence': 0.100338474}
2024-12-15 18:23:55,021 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 1, 'avg_loss': 1.4286617224835099, 'accuracy': 0.237012987012987, 'precision': 0.3117415599975412, 'recall': 0.237012987012987, 'f1': 0.25644464040726866, 'macro_accuracy': 0.237012987012987, 'macro_precision': 0.2273793417590294, 'macro_recall': 0.22736047183205024, 'macro_f1': 0.21171720816269624, 'question_accuracy': 0.237012987012987, 'mean_confidence': 0.38510713}
2024-12-15 18:30:39,534 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 2, 'avg_loss': 1.4283688855588261, 'accuracy': 0.26136363636363635, 'precision': 0.3389747345757701, 'recall': 0.26136363636363635, 'f1': 0.2835310686464925, 'macro_accuracy': 0.26136363636363635, 'macro_precision': 0.2472277694098859, 'macro_recall': 0.24306914476112837, 'macro_f1': 0.2315964670831004, 'question_accuracy': 0.2727272727272727, 'mean_confidence': 0.33194214}
2024-12-15 18:37:20,995 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 3, 'avg_loss': 1.4397258640378279, 'accuracy': 0.2662337662337662, 'precision': 0.3466427518187441, 'recall': 0.2662337662337662, 'f1': 0.28818358592196114, 'macro_accuracy': 0.2662337662337662, 'macro_precision': 0.25119038466601595, 'macro_recall': 0.2505275418139192, 'macro_f1': 0.23548469356000795, 'question_accuracy': 0.29545454545454547, 'mean_confidence': 0.3050114}
2024-12-15 18:44:05,746 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 4, 'avg_loss': 1.4516855438318614, 'accuracy': 0.2727272727272727, 'precision': 0.3455224120675125, 'recall': 0.2727272727272727, 'f1': 0.2911300864188976, 'macro_accuracy': 0.2727272727272727, 'macro_precision': 0.258084937130355, 'macro_recall': 0.26524531464510104, 'macro_f1': 0.24630390160185425, 'question_accuracy': 0.2987012987012987, 'mean_confidence': 0.41805393}
2024-12-15 18:50:47,082 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 5, 'avg_loss': 1.4867393468281271, 'accuracy': 0.25892857142857145, 'precision': 0.3384826178249095, 'recall': 0.25892857142857145, 'f1': 0.276692362278204, 'macro_accuracy': 0.25892857142857145, 'macro_precision': 0.2554934028327577, 'macro_recall': 0.2622897965532513, 'macro_f1': 0.2390272213757557, 'question_accuracy': 0.29545454545454547, 'mean_confidence': 0.38585985}
2024-12-15 18:57:29,718 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 6, 'avg_loss': 1.5137895047664642, 'accuracy': 0.25243506493506496, 'precision': 0.32691772029467125, 'recall': 0.25243506493506496, 'f1': 0.27286548428611707, 'macro_accuracy': 0.25243506493506496, 'macro_precision': 0.236988081047399, 'macro_recall': 0.2370690790668944, 'macro_f1': 0.22258800189771555, 'question_accuracy': 0.2597402597402597, 'mean_confidence': 0.99037725}
2024-12-15 19:04:09,781 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 7, 'avg_loss': 1.5216206748353496, 'accuracy': 0.2483766233766234, 'precision': 0.3296356929890073, 'recall': 0.2483766233766234, 'f1': 0.2704706717703764, 'macro_accuracy': 0.2483766233766234, 'macro_precision': 0.23732210842406526, 'macro_recall': 0.23314290562832388, 'macro_f1': 0.22015525660600535, 'question_accuracy': 0.2564935064935065, 'mean_confidence': 0.9801842}
2024-12-15 19:10:53,521 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 8, 'avg_loss': 1.5276398648325973, 'accuracy': 0.26136363636363635, 'precision': 0.3382554315884932, 'recall': 0.26136363636363635, 'f1': 0.28256530173662975, 'macro_accuracy': 0.26136363636363635, 'macro_precision': 0.24232551553731826, 'macro_recall': 0.24333815540859707, 'macro_f1': 0.2275355198738332, 'question_accuracy': 0.2824675324675325, 'mean_confidence': 0.99932456}
2024-12-15 19:17:36,399 - bert-base-uncased_baas-prompt_race_binary_cluster_suffix_ratio_50 - INFO - {'epoch': 9, 'avg_loss': 1.471112218959686, 'accuracy': 0.2637987012987013, 'precision': 0.3358264243933513, 'recall': 0.2637987012987013, 'f1': 0.2829721955604924, 'macro_accuracy': 0.2637987012987013, 'macro_precision': 0.24958024913239638, 'macro_recall': 0.2523099323625858, 'macro_f1': 0.2367822478079301, 'question_accuracy': 0.275974025974026, 'mean_confidence': 0.997007}

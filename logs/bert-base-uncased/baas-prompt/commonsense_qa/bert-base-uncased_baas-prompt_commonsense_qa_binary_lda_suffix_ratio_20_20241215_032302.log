2024-12-15 03:26:09,672 - bert-base-uncased_baas-prompt_commonsense_qa_binary_lda_suffix_ratio_20 - INFO - {'epoch': 0, 'avg_loss': 1.639118718081399, 'accuracy': 0.2, 'precision': 0.3200179110105581, 'recall': 0.2, 'f1': 0.22384884817787615, 'macro_accuracy': 0.2, 'macro_precision': 0.20202767520211742, 'macro_recall': 0.20113595217043492, 'macro_f1': 0.17945442584661817, 'question_accuracy': 0.14285714285714285, 'mean_confidence': 0.4814434}
2024-12-15 03:29:08,678 - bert-base-uncased_baas-prompt_commonsense_qa_binary_lda_suffix_ratio_20 - INFO - {'epoch': 1, 'avg_loss': 1.6584224289185123, 'accuracy': 0.20714285714285716, 'precision': 0.3219879901988761, 'recall': 0.20714285714285716, 'f1': 0.22777785201303968, 'macro_accuracy': 0.20714285714285716, 'macro_precision': 0.20551440047382244, 'macro_recall': 0.21420066523514797, 'macro_f1': 0.1865046853093782, 'question_accuracy': 0.14285714285714285, 'mean_confidence': 0.7509786}
2024-12-15 03:32:07,184 - bert-base-uncased_baas-prompt_commonsense_qa_binary_lda_suffix_ratio_20 - INFO - {'epoch': 2, 'avg_loss': 1.6700823122733517, 'accuracy': 0.20714285714285716, 'precision': 0.35222567383127734, 'recall': 0.20714285714285716, 'f1': 0.2351850375408684, 'macro_accuracy': 0.20714285714285716, 'macro_precision': 0.2195316337557717, 'macro_recall': 0.21234432234432238, 'macro_f1': 0.18823487019536228, 'question_accuracy': 0.2, 'mean_confidence': 0.55799717}
2024-12-15 03:35:05,500 - bert-base-uncased_baas-prompt_commonsense_qa_binary_lda_suffix_ratio_20 - INFO - {'epoch': 3, 'avg_loss': 1.6685508689598034, 'accuracy': 0.17142857142857143, 'precision': 0.2975022235078751, 'recall': 0.17142857142857143, 'f1': 0.19974448331748976, 'macro_accuracy': 0.17142857142857143, 'macro_precision': 0.18092964216634427, 'macro_recall': 0.15365247779040883, 'macro_f1': 0.1519177484455111, 'question_accuracy': 0.14285714285714285, 'mean_confidence': 0.81331015}
2024-12-15 03:38:05,026 - bert-base-uncased_baas-prompt_commonsense_qa_binary_lda_suffix_ratio_20 - INFO - {'epoch': 4, 'avg_loss': 1.6671746198676134, 'accuracy': 0.16785714285714284, 'precision': 0.29970335276967935, 'recall': 0.16785714285714284, 'f1': 0.1896388271681966, 'macro_accuracy': 0.16785714285714284, 'macro_precision': 0.17995238095238092, 'macro_recall': 0.1734823796892762, 'macro_f1': 0.15104505287195288, 'question_accuracy': 0.14285714285714285, 'mean_confidence': 0.78722686}
2024-12-15 03:41:06,104 - bert-base-uncased_baas-prompt_commonsense_qa_binary_lda_suffix_ratio_20 - INFO - {'epoch': 5, 'avg_loss': 2.396877779870441, 'accuracy': 0.18571428571428572, 'precision': 0.3380500764055662, 'recall': 0.18571428571428572, 'f1': 0.20766743113599706, 'macro_accuracy': 0.18571428571428572, 'macro_precision': 0.20350039223886873, 'macro_recall': 0.20841438255231357, 'macro_f1': 0.16906686526531886, 'question_accuracy': 0.18571428571428572, 'mean_confidence': 0.9764211}
2024-12-15 03:44:04,718 - bert-base-uncased_baas-prompt_commonsense_qa_binary_lda_suffix_ratio_20 - INFO - {'epoch': 6, 'avg_loss': 2.9181037031613464, 'accuracy': 0.20357142857142857, 'precision': 0.3656634984721717, 'recall': 0.20357142857142857, 'f1': 0.23826027597485197, 'macro_accuracy': 0.20357142857142857, 'macro_precision': 0.20725805062257038, 'macro_recall': 0.19469874952633573, 'macro_f1': 0.1702808964663794, 'question_accuracy': 0.22857142857142856, 'mean_confidence': 0.8032436}
2024-12-15 03:47:03,339 - bert-base-uncased_baas-prompt_commonsense_qa_binary_lda_suffix_ratio_20 - INFO - {'epoch': 7, 'avg_loss': 3.0943536080518053, 'accuracy': 0.19642857142857142, 'precision': 0.3258962992993299, 'recall': 0.19642857142857142, 'f1': 0.21511149951455932, 'macro_accuracy': 0.19642857142857142, 'macro_precision': 0.20527063783649777, 'macro_recall': 0.22493410803755629, 'macro_f1': 0.18097765668852145, 'question_accuracy': 0.11428571428571428, 'mean_confidence': 0.7013839}
2024-12-15 03:50:02,228 - bert-base-uncased_baas-prompt_commonsense_qa_binary_lda_suffix_ratio_20 - INFO - {'epoch': 8, 'avg_loss': 2.838133548190327, 'accuracy': 0.175, 'precision': 0.3018479527835996, 'recall': 0.175, 'f1': 0.1998587490567915, 'macro_accuracy': 0.175, 'macro_precision': 0.1813836465404105, 'macro_recall': 0.17737611047955876, 'macro_f1': 0.15435170301120474, 'question_accuracy': 0.08571428571428572, 'mean_confidence': 0.19020066}
2024-12-15 03:53:01,602 - bert-base-uncased_baas-prompt_commonsense_qa_binary_lda_suffix_ratio_20 - INFO - {'epoch': 9, 'avg_loss': 2.792622212369583, 'accuracy': 0.17142857142857143, 'precision': 0.3177083333333333, 'recall': 0.17142857142857143, 'f1': 0.20572745227123107, 'macro_accuracy': 0.17142857142857143, 'macro_precision': 0.1707854406130268, 'macro_recall': 0.14892467685571134, 'macro_f1': 0.13736638593145822, 'question_accuracy': 0.14285714285714285, 'mean_confidence': 0.81619084}

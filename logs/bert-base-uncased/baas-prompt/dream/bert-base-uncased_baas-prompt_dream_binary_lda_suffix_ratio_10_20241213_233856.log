2024-12-13 23:40:04,900 - bert-base-uncased_baas-prompt_dream_binary_lda_suffix_ratio_10 - INFO - {'epoch': 0, 'avg_loss': 1.1212237326722396, 'accuracy': 0.32056451612903225, 'precision': 0.45014562281317544, 'recall': 0.32056451612903225, 'f1': 0.3549731907756841, 'macro_accuracy': 0.32056451612903225, 'macro_precision': 0.30657364901860534, 'macro_recall': 0.3089710912140819, 'macro_f1': 0.2779255698561224, 'question_accuracy': 0.29838709677419356, 'mean_confidence': 0.8218948}
2024-12-13 23:40:59,969 - bert-base-uncased_baas-prompt_dream_binary_lda_suffix_ratio_10 - INFO - {'epoch': 1, 'avg_loss': 1.0917014517282184, 'accuracy': 0.30443548387096775, 'precision': 0.44958014890260584, 'recall': 0.30443548387096775, 'f1': 0.34164004931861547, 'macro_accuracy': 0.30443548387096775, 'macro_precision': 0.300276421504043, 'macro_recall': 0.2902802285979856, 'macro_f1': 0.26516157076916563, 'question_accuracy': 0.3548387096774194, 'mean_confidence': 0.45660788}
2024-12-13 23:41:54,498 - bert-base-uncased_baas-prompt_dream_binary_lda_suffix_ratio_10 - INFO - {'epoch': 2, 'avg_loss': 1.0958934953338222, 'accuracy': 0.33669354838709675, 'precision': 0.4644580516465218, 'recall': 0.33669354838709675, 'f1': 0.36767650978409566, 'macro_accuracy': 0.33669354838709675, 'macro_precision': 0.32727206933362285, 'macro_recall': 0.3414991031813462, 'macro_f1': 0.3010378420114504, 'question_accuracy': 0.4112903225806452, 'mean_confidence': 0.7310384}
2024-12-13 23:42:48,895 - bert-base-uncased_baas-prompt_dream_binary_lda_suffix_ratio_10 - INFO - {'epoch': 3, 'avg_loss': 1.106144284574609, 'accuracy': 0.3387096774193548, 'precision': 0.472581670849359, 'recall': 0.3387096774193548, 'f1': 0.3705413806125372, 'macro_accuracy': 0.3387096774193548, 'macro_precision': 0.32816642737231094, 'macro_recall': 0.34264354544728376, 'macro_f1': 0.3014916605258197, 'question_accuracy': 0.3629032258064516, 'mean_confidence': 0.5857262}
2024-12-13 23:43:43,000 - bert-base-uncased_baas-prompt_dream_binary_lda_suffix_ratio_10 - INFO - {'epoch': 4, 'avg_loss': 1.0835161322041562, 'accuracy': 0.3346774193548387, 'precision': 0.4733145732137668, 'recall': 0.3346774193548387, 'f1': 0.37019810611721066, 'macro_accuracy': 0.3346774193548387, 'macro_precision': 0.3204561704561705, 'macro_recall': 0.3265175115642405, 'macro_f1': 0.2907654431961841, 'question_accuracy': 0.3387096774193548, 'mean_confidence': 0.6557312}
2024-12-13 23:44:37,957 - bert-base-uncased_baas-prompt_dream_binary_lda_suffix_ratio_10 - INFO - {'epoch': 5, 'avg_loss': 1.090080399889695, 'accuracy': 0.35685483870967744, 'precision': 0.4867871854021924, 'recall': 0.35685483870967744, 'f1': 0.38999896344765334, 'macro_accuracy': 0.35685483870967744, 'macro_precision': 0.33893533284837635, 'macro_recall': 0.3518833191730388, 'macro_f1': 0.31428611147733887, 'question_accuracy': 0.3387096774193548, 'mean_confidence': 0.7303632}

2024-12-13 00:54:36,067 - bert-base-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 0, 'avg_loss': 1.1215682914382532, 'accuracy': 0.31451612903225806, 'precision': 0.44513955927769355, 'recall': 0.31451612903225806, 'f1': 0.35195322512881755, 'macro_accuracy': 0.31451612903225806, 'macro_precision': 0.2962171265707993, 'macro_recall': 0.28750481086929686, 'macro_f1': 0.26641263709707075, 'question_accuracy': 0.28225806451612906, 'mean_confidence': 0.7995121}
2024-12-13 00:55:30,425 - bert-base-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 1, 'avg_loss': 1.1238560626381322, 'accuracy': 0.3407258064516129, 'precision': 0.49361412277238886, 'recall': 0.3407258064516129, 'f1': 0.38212749854702716, 'macro_accuracy': 0.3407258064516129, 'macro_precision': 0.3319250194250194, 'macro_recall': 0.3211351473033716, 'macro_f1': 0.2951078638160358, 'question_accuracy': 0.3951612903225806, 'mean_confidence': 0.55229807}
2024-12-13 00:56:24,853 - bert-base-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 2, 'avg_loss': 1.0938680529594422, 'accuracy': 0.3084677419354839, 'precision': 0.4732877981113868, 'recall': 0.3084677419354839, 'f1': 0.3493590343881394, 'macro_accuracy': 0.3084677419354839, 'macro_precision': 0.31663105413105413, 'macro_recall': 0.296128793325055, 'macro_f1': 0.27284367735495557, 'question_accuracy': 0.3387096774193548, 'mean_confidence': 0.60032916}
2024-12-13 00:57:18,039 - bert-base-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 3, 'avg_loss': 1.1594408229777688, 'accuracy': 0.33669354838709675, 'precision': 0.500435745454701, 'recall': 0.33669354838709675, 'f1': 0.3786231374561829, 'macro_accuracy': 0.33669354838709675, 'macro_precision': 0.339845902354136, 'macro_recall': 0.3293357732610069, 'macro_f1': 0.2969674574510997, 'question_accuracy': 0.3790322580645161, 'mean_confidence': 0.5511678}
2024-12-13 00:58:10,918 - bert-base-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 4, 'avg_loss': 1.1441861987113953, 'accuracy': 0.3326612903225806, 'precision': 0.489028143902074, 'recall': 0.3326612903225806, 'f1': 0.37216871886077546, 'macro_accuracy': 0.3326612903225806, 'macro_precision': 0.32826900485922383, 'macro_recall': 0.3254790899650713, 'macro_f1': 0.28906535513009857, 'question_accuracy': 0.3629032258064516, 'mean_confidence': 0.65177834}
2024-12-13 00:59:04,197 - bert-base-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 5, 'avg_loss': 1.1727292004384493, 'accuracy': 0.34475806451612906, 'precision': 0.48947836734173233, 'recall': 0.34475806451612906, 'f1': 0.38607567933861486, 'macro_accuracy': 0.34475806451612906, 'macro_precision': 0.32995552804713113, 'macro_recall': 0.31922822763944253, 'macro_f1': 0.2953357184639884, 'question_accuracy': 0.3548387096774194, 'mean_confidence': 0.7917156}
2024-12-13 00:59:56,625 - bert-base-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 6, 'avg_loss': 1.1345404944921795, 'accuracy': 0.36088709677419356, 'precision': 0.492714491820719, 'recall': 0.36088709677419356, 'f1': 0.39897074419090955, 'macro_accuracy': 0.36088709677419356, 'macro_precision': 0.3382133606891333, 'macro_recall': 0.33550312615733174, 'macro_f1': 0.31037025604088425, 'question_accuracy': 0.3870967741935484, 'mean_confidence': 0.52536833}
2024-12-13 01:00:49,131 - bert-base-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 7, 'avg_loss': 1.111111963422675, 'accuracy': 0.35080645161290325, 'precision': 0.4998492720422987, 'recall': 0.35080645161290325, 'f1': 0.3926051980643006, 'macro_accuracy': 0.35080645161290325, 'macro_precision': 0.3389118804447084, 'macro_recall': 0.32611521396568127, 'macro_f1': 0.3037279898157796, 'question_accuracy': 0.3790322580645161, 'mean_confidence': 0.51310503}
2024-12-13 01:01:41,466 - bert-base-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 8, 'avg_loss': 1.158221791919909, 'accuracy': 0.3810483870967742, 'precision': 0.5073236862983407, 'recall': 0.3810483870967742, 'f1': 0.41717578569170594, 'macro_accuracy': 0.3810483870967742, 'macro_precision': 0.35153418010560866, 'macro_recall': 0.3537488472067911, 'macro_f1': 0.32810332371543427, 'question_accuracy': 0.41935483870967744, 'mean_confidence': 0.6797453}
2024-12-13 01:02:33,775 - bert-base-uncased_baas-prompt_dream_binary_cluster - INFO - {'epoch': 9, 'avg_loss': 1.1038878666727165, 'accuracy': 0.3810483870967742, 'precision': 0.5118980922019714, 'recall': 0.3810483870967742, 'f1': 0.4200036962458001, 'macro_accuracy': 0.3810483870967742, 'macro_precision': 0.349073626960124, 'macro_recall': 0.34357739871758564, 'macro_f1': 0.3230981286088677, 'question_accuracy': 0.45161290322580644, 'mean_confidence': 0.53163767}

2024-12-15 22:59:13,938 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 0, 'avg_loss': 1.6260476202556962, 'accuracy': 0.20357142857142857, 'precision': 0.31120848908885845, 'recall': 0.20357142857142857, 'f1': 0.22806726932609403, 'macro_accuracy': 0.20357142857142857, 'macro_precision': 0.1890825152366702, 'macro_recall': 0.1908950009446995, 'macro_f1': 0.17173660449185063, 'question_accuracy': 0.2857142857142857, 'mean_confidence': 0.41254354}
2024-12-15 23:01:18,936 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 1, 'avg_loss': 1.6129704623630172, 'accuracy': 0.20714285714285716, 'precision': 0.3100803919410599, 'recall': 0.20714285714285716, 'f1': 0.23233608389923088, 'macro_accuracy': 0.20714285714285716, 'macro_precision': 0.19202172038662568, 'macro_recall': 0.18394417848358963, 'macro_f1': 0.1737421140319691, 'question_accuracy': 0.24285714285714285, 'mean_confidence': 0.43818855}
2024-12-15 23:03:24,803 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 2, 'avg_loss': 1.5943143654026484, 'accuracy': 0.21785714285714286, 'precision': 0.3243299340988078, 'recall': 0.21785714285714286, 'f1': 0.24436105345617642, 'macro_accuracy': 0.21785714285714286, 'macro_precision': 0.20218985433878484, 'macro_recall': 0.19628422449986135, 'macro_f1': 0.1837966689522377, 'question_accuracy': 0.22857142857142856, 'mean_confidence': 0.3439613}
2024-12-15 23:05:30,154 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 3, 'avg_loss': 1.5939300844543858, 'accuracy': 0.2357142857142857, 'precision': 0.3618532560611898, 'recall': 0.2357142857142857, 'f1': 0.27161552314960674, 'macro_accuracy': 0.2357142857142857, 'macro_precision': 0.2135639962707688, 'macro_recall': 0.19485344398177343, 'macro_f1': 0.18904620139944125, 'question_accuracy': 0.2714285714285714, 'mean_confidence': 0.15010004}
2024-12-15 23:07:35,398 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 4, 'avg_loss': 1.646520256604019, 'accuracy': 0.25357142857142856, 'precision': 0.3861891437913193, 'recall': 0.25357142857142856, 'f1': 0.29230790238545623, 'macro_accuracy': 0.25357142857142856, 'macro_precision': 0.22876509054325958, 'macro_recall': 0.20276455552910946, 'macro_f1': 0.20191618036906914, 'question_accuracy': 0.21428571428571427, 'mean_confidence': 0.23303571}
2024-12-15 23:09:40,619 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 5, 'avg_loss': 1.6431033266218085, 'accuracy': 0.21071428571428572, 'precision': 0.31898757362861385, 'recall': 0.21071428571428572, 'f1': 0.23723095607052894, 'macro_accuracy': 0.21071428571428572, 'macro_precision': 0.20900430480372342, 'macro_recall': 0.19852573876727758, 'macro_f1': 0.1870626567132866, 'question_accuracy': 0.17142857142857143, 'mean_confidence': 0.8184099}
2024-12-15 23:11:46,933 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 6, 'avg_loss': 1.639089921391324, 'accuracy': 0.20357142857142857, 'precision': 0.32610316076668905, 'recall': 0.20357142857142857, 'f1': 0.2340742237304223, 'macro_accuracy': 0.20357142857142857, 'macro_precision': 0.20340554100533273, 'macro_recall': 0.18186084044720682, 'macro_f1': 0.1755661237023291, 'question_accuracy': 0.14285714285714285, 'mean_confidence': 0.46984816}
2024-12-15 23:13:52,296 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 7, 'avg_loss': 1.702451614761039, 'accuracy': 0.21428571428571427, 'precision': 0.3452289365567016, 'recall': 0.21428571428571427, 'f1': 0.2451691755304235, 'macro_accuracy': 0.21428571428571427, 'macro_precision': 0.2044640723672982, 'macro_recall': 0.1914790886062697, 'macro_f1': 0.1786785202877157, 'question_accuracy': 0.22857142857142856, 'mean_confidence': 0.28495878}
2024-12-15 23:15:57,717 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 8, 'avg_loss': 1.6063819757025493, 'accuracy': 0.22857142857142856, 'precision': 0.33543272117576367, 'recall': 0.22857142857142856, 'f1': 0.25448237806960583, 'macro_accuracy': 0.22857142857142856, 'macro_precision': 0.21656858029894993, 'macro_recall': 0.2111536408555133, 'macro_f1': 0.1977744734957802, 'question_accuracy': 0.21428571428571427, 'mean_confidence': 0.10033376}
2024-12-15 23:18:03,043 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_5 - INFO - {'epoch': 9, 'avg_loss': 1.6544185041597015, 'accuracy': 0.20357142857142857, 'precision': 0.32107654916725614, 'recall': 0.20357142857142857, 'f1': 0.23089374697631412, 'macro_accuracy': 0.20357142857142857, 'macro_precision': 0.19145578908909977, 'macro_recall': 0.1760596592047675, 'macro_f1': 0.1675156930467681, 'question_accuracy': 0.18571428571428572, 'mean_confidence': 0.25788733}

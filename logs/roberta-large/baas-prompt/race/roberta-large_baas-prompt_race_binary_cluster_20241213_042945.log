2024-12-13 04:39:10,796 - roberta-large_baas-prompt_race_binary_cluster - INFO - {'epoch': 0, 'avg_loss': 1.8286126143035666, 'accuracy': 0.25243506493506496, 'precision': 0.32641156267375454, 'recall': 0.25243506493506496, 'f1': 0.2700953199050757, 'macro_accuracy': 0.25243506493506496, 'macro_precision': 0.2450315068667414, 'macro_recall': 0.25080794361249537, 'macro_f1': 0.23078264800722442, 'question_accuracy': 0.2435064935064935, 'mean_confidence': 0.98469996}
2024-12-13 04:48:22,810 - roberta-large_baas-prompt_race_binary_cluster - INFO - {'epoch': 1, 'avg_loss': 1.4730876607728074, 'accuracy': 0.2532467532467532, 'precision': 0.3301000192585517, 'recall': 0.2532467532467532, 'f1': 0.2752454279991673, 'macro_accuracy': 0.2532467532467532, 'macro_precision': 0.24214765471925176, 'macro_recall': 0.23681814640326931, 'macro_f1': 0.22512872566603767, 'question_accuracy': 0.2662337662337662, 'mean_confidence': 0.99892116}
2024-12-13 04:57:37,749 - roberta-large_baas-prompt_race_binary_cluster - INFO - {'epoch': 2, 'avg_loss': 1.6133861152493223, 'accuracy': 0.25892857142857145, 'precision': 0.33247223851839525, 'recall': 0.25892857142857145, 'f1': 0.2778290976262206, 'macro_accuracy': 0.25892857142857145, 'macro_precision': 0.24964122113564746, 'macro_recall': 0.2516762153380543, 'macro_f1': 0.23602539357107627, 'question_accuracy': 0.2694805194805195, 'mean_confidence': 0.06283504}
2024-12-13 05:06:50,875 - roberta-large_baas-prompt_race_binary_cluster - INFO - {'epoch': 3, 'avg_loss': 1.8353669799799126, 'accuracy': 0.2702922077922078, 'precision': 0.3490538381517082, 'recall': 0.2702922077922078, 'f1': 0.29161851642425973, 'macro_accuracy': 0.2702922077922078, 'macro_precision': 0.258530351034049, 'macro_recall': 0.2580053038221165, 'macro_f1': 0.24267962439341006, 'question_accuracy': 0.2564935064935065, 'mean_confidence': 0.008208965}
2024-12-13 05:16:08,844 - roberta-large_baas-prompt_race_binary_cluster - INFO - {'epoch': 4, 'avg_loss': 2.11646070450805, 'accuracy': 0.32061688311688313, 'precision': 0.34786552351454475, 'recall': 0.32061688311688313, 'f1': 0.33183101680026295, 'macro_accuracy': 0.32061688311688313, 'macro_precision': 0.26083597738168274, 'macro_recall': 0.2583218273928203, 'macro_f1': 0.2562700947836031, 'question_accuracy': 0.275974025974026, 'mean_confidence': 0.99389905}
2024-12-13 05:25:21,347 - roberta-large_baas-prompt_race_binary_cluster - INFO - {'epoch': 5, 'avg_loss': 2.336277897955725, 'accuracy': 0.4496753246753247, 'precision': 0.3262328779529788, 'recall': 0.4496753246753247, 'f1': 0.35305047227019426, 'macro_accuracy': 0.4496753246753247, 'macro_precision': 0.2244781275400872, 'macro_recall': 0.2433105415306922, 'macro_f1': 0.20517818369830423, 'question_accuracy': 0.5064935064935064, 'mean_confidence': 0.9999998}
2024-12-13 05:34:34,995 - roberta-large_baas-prompt_race_binary_cluster - INFO - {'epoch': 6, 'avg_loss': 2.673228441626268, 'accuracy': 0.3425324675324675, 'precision': 0.33835153857807115, 'recall': 0.34253246753246747, 'f1': 0.3400990168611763, 'macro_accuracy': 0.3425324675324675, 'macro_precision': 0.24506833298470482, 'macro_recall': 0.2463966786630219, 'macro_f1': 0.24524000879395827, 'question_accuracy': 0.3409090909090909, 'mean_confidence': 0.82569236}
2024-12-13 05:43:46,618 - roberta-large_baas-prompt_race_binary_cluster - INFO - {'epoch': 7, 'avg_loss': 2.9736006315526047, 'accuracy': 0.23863636363636365, 'precision': 0.31891139801782625, 'recall': 0.23863636363636365, 'f1': 0.2576213249500474, 'macro_accuracy': 0.23863636363636365, 'macro_precision': 0.23379182629793727, 'macro_recall': 0.23581188672075967, 'macro_f1': 0.21595947547903654, 'question_accuracy': 0.24675324675324675, 'mean_confidence': 0.8984916}
2024-12-13 05:52:59,254 - roberta-large_baas-prompt_race_binary_cluster - INFO - {'epoch': 8, 'avg_loss': 3.4206334438946087, 'accuracy': 0.49756493506493504, 'precision': 0.3240035673546312, 'recall': 0.49756493506493504, 'f1': 0.33529406574882925, 'macro_accuracy': 0.49756493506493504, 'macro_precision': 0.2085379159847245, 'macro_recall': 0.24850218356372036, 'macro_f1': 0.1681425831202046, 'question_accuracy': 0.5324675324675324, 'mean_confidence': 0.99998546}
2024-12-13 06:02:12,572 - roberta-large_baas-prompt_race_binary_cluster - INFO - {'epoch': 9, 'avg_loss': 3.6220266089581887, 'accuracy': 0.2840909090909091, 'precision': 0.35466943755701336, 'recall': 0.2840909090909091, 'f1': 0.30611762985370167, 'macro_accuracy': 0.2840909090909091, 'macro_precision': 0.2613396962387433, 'macro_recall': 0.25800540426357005, 'macro_f1': 0.24743079586895075, 'question_accuracy': 0.275974025974026, 'mean_confidence': 0.9547719}

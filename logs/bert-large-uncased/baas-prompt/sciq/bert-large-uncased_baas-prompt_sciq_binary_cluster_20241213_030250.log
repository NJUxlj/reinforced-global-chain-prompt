2024-12-13 03:07:37,873 - bert-large-uncased_baas-prompt_sciq_binary_cluster - INFO - {'epoch': 0, 'avg_loss': 1.3766638381140572, 'accuracy': 0.42916666666666664, 'precision': 0.6091268793800747, 'recall': 0.42916666666666664, 'f1': 0.44328957428448285, 'macro_accuracy': 0.42916666666666664, 'macro_precision': 0.42942252477540066, 'macro_recall': 0.5352208306648639, 'macro_f1': 0.4149533954256307, 'question_accuracy': 0.48333333333333334, 'mean_confidence': 0.7844996}
2024-12-13 03:12:17,182 - bert-large-uncased_baas-prompt_sciq_binary_cluster - INFO - {'epoch': 1, 'avg_loss': 1.2692689509182187, 'accuracy': 0.49583333333333335, 'precision': 0.6437922255340288, 'recall': 0.49583333333333335, 'f1': 0.5140432098765432, 'macro_accuracy': 0.49583333333333335, 'macro_precision': 0.4700522724088298, 'macro_recall': 0.5753633812867162, 'macro_f1': 0.47133190883190884, 'question_accuracy': 0.5333333333333333, 'mean_confidence': 0.74785894}
2024-12-13 03:16:55,779 - bert-large-uncased_baas-prompt_sciq_binary_cluster - INFO - {'epoch': 2, 'avg_loss': 1.2218965531050503, 'accuracy': 0.26666666666666666, 'precision': 0.44970471150329794, 'recall': 0.26666666666666666, 'f1': 0.31375347246400564, 'macro_accuracy': 0.26666666666666666, 'macro_precision': 0.2515619549002739, 'macro_recall': 0.23146414466661924, 'macro_f1': 0.21319447418494059, 'question_accuracy': 0.31666666666666665, 'mean_confidence': 0.27196613}
2024-12-13 03:21:34,611 - bert-large-uncased_baas-prompt_sciq_binary_cluster - INFO - {'epoch': 3, 'avg_loss': 1.3676356244218217, 'accuracy': 0.42916666666666664, 'precision': 0.5907672192715249, 'recall': 0.42916666666666664, 'f1': 0.44388748486120216, 'macro_accuracy': 0.42916666666666664, 'macro_precision': 0.42137422218750814, 'macro_recall': 0.5180358879480064, 'macro_f1': 0.4120509730857348, 'question_accuracy': 0.48333333333333334, 'mean_confidence': 0.5769686}
2024-12-13 03:26:14,370 - bert-large-uncased_baas-prompt_sciq_binary_cluster - INFO - {'epoch': 4, 'avg_loss': 1.2597227902202817, 'accuracy': 0.5416666666666666, 'precision': 0.6791815220298827, 'recall': 0.5416666666666666, 'f1': 0.5498580246913581, 'macro_accuracy': 0.5416666666666666, 'macro_precision': 0.5167493822206937, 'macro_recall': 0.6630524966990046, 'macro_f1': 0.5297222222222222, 'question_accuracy': 0.65, 'mean_confidence': 0.75789696}
2024-12-13 03:30:52,825 - bert-large-uncased_baas-prompt_sciq_binary_cluster - INFO - {'epoch': 5, 'avg_loss': 1.2008817403853596, 'accuracy': 0.48333333333333334, 'precision': 0.6678550654592321, 'recall': 0.48333333333333334, 'f1': 0.5042875834776703, 'macro_accuracy': 0.48333333333333334, 'macro_precision': 0.4738120675620676, 'macro_recall': 0.5757054642346039, 'macro_f1': 0.4603439483357726, 'question_accuracy': 0.55, 'mean_confidence': 0.9282901}
2024-12-13 03:35:31,137 - bert-large-uncased_baas-prompt_sciq_binary_cluster - INFO - {'epoch': 6, 'avg_loss': 1.266124318261723, 'accuracy': 0.5333333333333333, 'precision': 0.7388878243796276, 'recall': 0.5333333333333333, 'f1': 0.5483902535318447, 'macro_accuracy': 0.5333333333333333, 'macro_precision': 0.5277269178908522, 'macro_recall': 0.6538503542146004, 'macro_f1': 0.5141866132000416, 'question_accuracy': 0.65, 'mean_confidence': 0.6888828}
2024-12-13 03:40:09,431 - bert-large-uncased_baas-prompt_sciq_binary_cluster - INFO - {'epoch': 7, 'avg_loss': 1.2348754386325458, 'accuracy': 0.5291666666666667, 'precision': 0.7044378406010954, 'recall': 0.5291666666666667, 'f1': 0.5435259015496948, 'macro_accuracy': 0.5291666666666667, 'macro_precision': 0.5161358579488944, 'macro_recall': 0.6462023480553776, 'macro_f1': 0.513132433898517, 'question_accuracy': 0.6666666666666666, 'mean_confidence': 0.59255105}
2024-12-13 03:44:48,451 - bert-large-uncased_baas-prompt_sciq_binary_cluster - INFO - {'epoch': 8, 'avg_loss': 1.2028918010847909, 'accuracy': 0.49583333333333335, 'precision': 0.6624125118136914, 'recall': 0.49583333333333335, 'f1': 0.503225870253639, 'macro_accuracy': 0.49583333333333335, 'macro_precision': 0.4855895254908254, 'macro_recall': 0.6115454786245721, 'macro_f1': 0.4828108630661715, 'question_accuracy': 0.6, 'mean_confidence': 0.8366639}
2024-12-13 03:49:28,591 - bert-large-uncased_baas-prompt_sciq_binary_cluster - INFO - {'epoch': 9, 'avg_loss': 1.19883312694319, 'accuracy': 0.525, 'precision': 0.7192051091269841, 'recall': 0.525, 'f1': 0.533618028122694, 'macro_accuracy': 0.525, 'macro_precision': 0.5240699404761905, 'macro_recall': 0.666316182981886, 'macro_f1': 0.5150364491393782, 'question_accuracy': 0.5833333333333334, 'mean_confidence': 0.8750617}

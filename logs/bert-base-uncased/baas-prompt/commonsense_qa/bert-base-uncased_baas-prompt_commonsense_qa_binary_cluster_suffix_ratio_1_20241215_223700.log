2024-12-15 22:39:00,979 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 0, 'avg_loss': 1.6282031453753774, 'accuracy': 0.21785714285714286, 'precision': 0.29157366722633044, 'recall': 0.21785714285714286, 'f1': 0.23379188063398587, 'macro_accuracy': 0.21785714285714286, 'macro_precision': 0.2145348458326703, 'macro_recall': 0.2223192339896821, 'macro_f1': 0.20054144685723632, 'question_accuracy': 0.22857142857142856, 'mean_confidence': 0.33212996}
2024-12-15 22:40:52,458 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 1, 'avg_loss': 1.651230704627539, 'accuracy': 0.15357142857142858, 'precision': 0.24235160355327712, 'recall': 0.15357142857142858, 'f1': 0.1651177732148018, 'macro_accuracy': 0.15357142857142858, 'macro_precision': 0.1677309024358145, 'macro_recall': 0.17305704316481402, 'macro_f1': 0.1463135812585556, 'question_accuracy': 0.14285714285714285, 'mean_confidence': 0.12618108}
2024-12-15 22:42:43,236 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 2, 'avg_loss': 1.6834778648458029, 'accuracy': 0.21428571428571427, 'precision': 0.29788572628003995, 'recall': 0.21428571428571427, 'f1': 0.2336654487654756, 'macro_accuracy': 0.21428571428571427, 'macro_precision': 0.21022119492699773, 'macro_recall': 0.20806519534539952, 'macro_f1': 0.19407317987518488, 'question_accuracy': 0.15714285714285714, 'mean_confidence': 0.57195055}
2024-12-15 22:44:34,110 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 3, 'avg_loss': 1.6593948245832795, 'accuracy': 0.20357142857142857, 'precision': 0.27402134318247273, 'recall': 0.20357142857142857, 'f1': 0.2229377518804919, 'macro_accuracy': 0.20357142857142857, 'macro_precision': 0.18132663202430646, 'macro_recall': 0.17572276938414205, 'macro_f1': 0.1690935477288294, 'question_accuracy': 0.18571428571428572, 'mean_confidence': 0.4004388}
2024-12-15 22:46:25,810 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 4, 'avg_loss': 1.6614490484720783, 'accuracy': 0.225, 'precision': 0.3033970862165672, 'recall': 0.225, 'f1': 0.2533562199577266, 'macro_accuracy': 0.225, 'macro_precision': 0.1883049882488535, 'macro_recall': 0.16779643121106536, 'macro_f1': 0.1701187965298116, 'question_accuracy': 0.3142857142857143, 'mean_confidence': 0.46190724}
2024-12-15 22:48:16,777 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 5, 'avg_loss': 1.6416681926501424, 'accuracy': 0.25357142857142856, 'precision': 0.35212591850757713, 'recall': 0.25357142857142856, 'f1': 0.28506992001579684, 'macro_accuracy': 0.25357142857142856, 'macro_precision': 0.21927923253589116, 'macro_recall': 0.20160581996940477, 'macro_f1': 0.1992590685511442, 'question_accuracy': 0.32857142857142857, 'mean_confidence': 0.7952393}
2024-12-15 22:50:07,667 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 6, 'avg_loss': 1.6985690299617617, 'accuracy': 0.20357142857142857, 'precision': 0.2839498931551529, 'recall': 0.20357142857142857, 'f1': 0.22249157753094148, 'macro_accuracy': 0.20357142857142857, 'macro_precision': 0.20115509293047246, 'macro_recall': 0.20034597657966913, 'macro_f1': 0.18532470065399106, 'question_accuracy': 0.14285714285714285, 'mean_confidence': 0.91160846}
2024-12-15 22:51:58,171 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 7, 'avg_loss': 1.6656496669901044, 'accuracy': 0.20357142857142857, 'precision': 0.27126589111765986, 'recall': 0.20357142857142857, 'f1': 0.22514923384894012, 'macro_accuracy': 0.20357142857142857, 'macro_precision': 0.17455990643258107, 'macro_recall': 0.1673904796281427, 'macro_f1': 0.16315718540765484, 'question_accuracy': 0.22857142857142856, 'mean_confidence': 0.9295194}
2024-12-15 22:53:49,370 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 8, 'avg_loss': 1.6713567319277085, 'accuracy': 0.225, 'precision': 0.291445905285191, 'recall': 0.225, 'f1': 0.24453571690342935, 'macro_accuracy': 0.225, 'macro_precision': 0.20181841967556252, 'macro_recall': 0.20667619391385697, 'macro_f1': 0.19144503148315986, 'question_accuracy': 0.2, 'mean_confidence': 0.9381135}
2024-12-15 22:55:40,728 - bert-base-uncased_baas-prompt_commonsense_qa_binary_cluster_suffix_ratio_1 - INFO - {'epoch': 9, 'avg_loss': 1.7021766902976914, 'accuracy': 0.225, 'precision': 0.30765376675290457, 'recall': 0.225, 'f1': 0.2498950581430831, 'macro_accuracy': 0.225, 'macro_precision': 0.20774471776745673, 'macro_recall': 0.1990731191667096, 'macro_f1': 0.1905213396113503, 'question_accuracy': 0.14285714285714285, 'mean_confidence': 0.98565453}

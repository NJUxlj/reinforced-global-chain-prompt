2024-12-15 02:59:55,076 - bert-base-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 0, 'avg_loss': 1.6455181723362522, 'accuracy': 0.2392857142857143, 'precision': 0.35394407169578146, 'recall': 0.2392857142857143, 'f1': 0.26547651949199386, 'macro_accuracy': 0.2392857142857143, 'macro_precision': 0.2325567473306835, 'macro_recall': 0.2484400790843627, 'macro_f1': 0.2128028271958915, 'question_accuracy': 0.21428571428571427, 'mean_confidence': 0.72076344}
2024-12-15 03:02:17,880 - bert-base-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 1, 'avg_loss': 1.6256733509270769, 'accuracy': 0.20357142857142857, 'precision': 0.29339860258543765, 'recall': 0.20357142857142857, 'f1': 0.2316942359468059, 'macro_accuracy': 0.20357142857142857, 'macro_precision': 0.17101716770130077, 'macro_recall': 0.16719667700567736, 'macro_f1': 0.1552990498935673, 'question_accuracy': 0.24285714285714285, 'mean_confidence': 0.59635013}
2024-12-15 03:04:42,325 - bert-base-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 2, 'avg_loss': 1.622919331255712, 'accuracy': 0.2, 'precision': 0.29953060494812167, 'recall': 0.2, 'f1': 0.22898546404903816, 'macro_accuracy': 0.2, 'macro_precision': 0.17010686771603672, 'macro_recall': 0.15449619996009506, 'macro_f1': 0.14941137437642898, 'question_accuracy': 0.17142857142857143, 'mean_confidence': 0.6098621}
2024-12-15 03:07:05,480 - bert-base-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 3, 'avg_loss': 1.6061864918784092, 'accuracy': 0.22857142857142856, 'precision': 0.36860261949004336, 'recall': 0.22857142857142856, 'f1': 0.2665659024345269, 'macro_accuracy': 0.22857142857142856, 'macro_precision': 0.21296401367395285, 'macro_recall': 0.19257078594620086, 'macro_f1': 0.1813565713835789, 'question_accuracy': 0.21428571428571427, 'mean_confidence': 0.621922}
2024-12-15 03:09:29,043 - bert-base-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 4, 'avg_loss': 1.6304348330748708, 'accuracy': 0.21428571428571427, 'precision': 0.34438316075184333, 'recall': 0.21428571428571427, 'f1': 0.2525144775098124, 'macro_accuracy': 0.21428571428571427, 'macro_precision': 0.17945637473452533, 'macro_recall': 0.1699187390034645, 'macro_f1': 0.1528308256619362, 'question_accuracy': 0.18571428571428572, 'mean_confidence': 0.5642127}
2024-12-15 03:11:52,835 - bert-base-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 5, 'avg_loss': 1.653776694285242, 'accuracy': 0.24642857142857144, 'precision': 0.3505777207693584, 'recall': 0.24642857142857144, 'f1': 0.28026671299057454, 'macro_accuracy': 0.24642857142857144, 'macro_precision': 0.20123976294708004, 'macro_recall': 0.19514066496163682, 'macro_f1': 0.18348465774889428, 'question_accuracy': 0.24285714285714285, 'mean_confidence': 0.59432846}
2024-12-15 03:14:15,920 - bert-base-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 6, 'avg_loss': 1.6292554679277695, 'accuracy': 0.2, 'precision': 0.35730661548484793, 'recall': 0.2, 'f1': 0.24322855160926657, 'macro_accuracy': 0.2, 'macro_precision': 0.18512675130449074, 'macro_recall': 0.15552375251673284, 'macro_f1': 0.1475500306952181, 'question_accuracy': 0.22857142857142856, 'mean_confidence': 0.99383414}
2024-12-15 03:16:38,957 - bert-base-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 7, 'avg_loss': 1.7236621009283943, 'accuracy': 0.21071428571428572, 'precision': 0.3220787023598848, 'recall': 0.21071428571428572, 'f1': 0.24384801428359504, 'macro_accuracy': 0.21071428571428572, 'macro_precision': 0.18591060465609854, 'macro_recall': 0.17058769113565872, 'macro_f1': 0.16482841319289915, 'question_accuracy': 0.2714285714285714, 'mean_confidence': 0.941991}
2024-12-15 03:19:01,827 - bert-base-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 8, 'avg_loss': 1.685197881569988, 'accuracy': 0.19285714285714287, 'precision': 0.3145249625273838, 'recall': 0.19285714285714287, 'f1': 0.22130823430851176, 'macro_accuracy': 0.19285714285714287, 'macro_precision': 0.18544794188861985, 'macro_recall': 0.1763095173314469, 'macro_f1': 0.1591966283708792, 'question_accuracy': 0.15714285714285714, 'mean_confidence': 0.82648265}
2024-12-15 03:21:26,333 - bert-base-uncased_baas-prompt_commonsense_qa_binary_normal_suffix_ratio_10 - INFO - {'epoch': 9, 'avg_loss': 1.647575515665506, 'accuracy': 0.21071428571428572, 'precision': 0.3238368881728789, 'recall': 0.21071428571428572, 'f1': 0.24320748150570942, 'macro_accuracy': 0.21071428571428572, 'macro_precision': 0.17855068460617074, 'macro_recall': 0.15979158731022475, 'macro_f1': 0.1560744951673467, 'question_accuracy': 0.24285714285714285, 'mean_confidence': 0.8622116}
